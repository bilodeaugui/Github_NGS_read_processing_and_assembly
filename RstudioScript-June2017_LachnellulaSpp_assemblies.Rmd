# Installing the required packages for R:
# This is to be done in the R command line and not in R studio
#source("https://www.Bioconductor.org/biocLite.R")
#biocLite("BiocUpgrade")


Getting started in R: Set the working directory > setwd("~/") Check version installed
```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy = TRUE, fig.align='center')
```


This will help us when finding our files to source functions:
```{r sourcing_my_functions}
install.packages("rprojroot")
library(rprojroot)
# We specify ours is an RStudio project
# The root object contains a function that will help us locate our package r files
# regarless of our current working directory
root <- rprojroot::is_rstudio_project
scriptsPath <- root$make_fix_file(".")("R")
scripts  <- dir(root$find_file("R", path = root$find_file()))
scriptsl <- paste(scriptsPath, scripts, sep = "//")
lapply(scriptsl, source)
```

User: 
Define the path to the shared folder where the main working directory will be.
```{r setting_the_main_directory, cache=TRUE}
sharedPath <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/"
```

User:
Specify the name and path of the csv file you would like to use for generation of the 
metadata file if not using the csv file generated by sequencing service:
*Note: I suggest saving the file in the references folder in the shared path. Getting more specific
and making a directory just for these tables is fine too - but the table will be copied to the new
directory for this analysis later in the script. It's just important to have a raw, untouched 
reference for this data kept in a place where you will remember and keep all the other ones you use.
```{r metadata_name_and_path, cache=TRUE}
metadataFileAlternate <- "lachnellula_metadata_IonT_2017.csv"
metadataPath <- paste(sharedPath, "References/", metadataFileAlternate, sep = "")
```

User:
Define the the folder in the shared folder that will hold the analyses of the 
time-course/dataset you will be working with. In our case, we have two different 
time-course experiments, Oosporogenesis and Oospore Conversion. Below we set 
which one the script will run analyses for. We also get the user to specify what 
the name of the directory that will hold the reads will be. In the case below, 
we are calling the sequencing data directory (seqDataDir) "MiSeq_data_Sci2" 
because sequencing of oospore conversion time-course reads was done on the 
in-house MiSeq and was the second run we had done on this instrument for the 
overall project. We also added Sci2 because the sequencing libraries were made 
on the SciClone robotics instrument, and also represent the second time we 
generated libraries on that instrument:
```{r analysis_and_sequence_directory, cache=TRUE}
analysis   <- "Lachnellula_species_GenomeAn_IonTorrent_2017/"
seqDataDir <- "IonTorrent_data_2017"
```

User needs to specify the adapter sequences attached to the sequencing 
reads. This will depend on how the libraries were prepared. Specify which sequencing platform was 
used to generate the reads: 
1 - MiSeq
2 - HiSeq
3 - Ion Torrent

Also specify the library layout - paired-end or single reads (Illumina only):
1 - single
2 - paired-end
```{r sequencing_platform_used, cache=TRUE}
platform      <- 3
libraryLayout <- 1
```

User:
Specify the read-processing and quality assessment tool to be used.
1 - FastQC
2 - PrinSeq
```{r read_processing_tool, cache = TRUE}
readProc <- 2
```

User:
Specify which tool to use for assembly:
1 - Newbler (for 454 and Ion Torrent reads)
2 - SPADES (for Illumina reads, mainly)
```{r assembler, cache = TRUE}
assembler <- 2
```

User:
The following paths are to directories where the references, tools and general 
requirements are located, this depends on the directories actually having been 
put there:
```{r user_tools_and_references_dir, cache=TRUE}
toolsDirPath     <- paste(sharedPath, "tools/", sep = "")
referencesPath   <- paste(sharedPath, "References/", sep = "")
fastqPEValidatorPath <- paste(toolsDirPath, "FastqPairedEndValidator.pl", sep = "")
```

We prepared our libraries using the Mondrian and SciClone with library 
kits, instruments and kits by NuGen. NuGen kits are designed to work with 
Illumina sequencing platforms and generate libraries with the sequence 
structure:

5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 
   (N) 
   AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <- region to select as forward adapter
   XXXXXX 
   ATCTCGTATGCCGTCTTCTGCTTG 3'
   
3' TTACTATGCCGCTGGTGGCTCTAGATGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA 
   (N) 
   TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG <- region to select as reverse adapter
   XXXXXX 
   TAGAGCATACGGCAGAAGACGAAC 5'

Where each string of ‘X’ is the unique 4-, 6, or 8-base barcode from the 
L2 adaptor mix of the library construction system (where applicable) 
and (N) is the library insert.

We will need to remove any adapter sequences from our reads. We will
be doing this with SeqPrep. SeqPrep specifies that the user must first 
ensure the adapter sequences they choose are correct by doing a "grep"
on the reads first:

Before running SeqPrep make sure to check that the program's defaults 
are indeed the adapters you are looking for. Try copying the default 
forward adapter from this file and grep it against your reads doing a 
word count, also try the same with the reverse adapter with grep. You 
should see some hits. You can also try using (and validating with grep) 
-A GATCGGAAGAGCACACG -B AGATCGGAAGAGCGTCGT as parameters. To find a 
list of Illumina adapter sequences you should write to Illumina tech 
support TechSupport@illumina.com (they do not like people to share the 
list of sequences outside of their institution).

Chose about 20bp of an adapter sequence where:
1. You see the most hits with grep
2. When you run a command like:
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | head 
   you see the adapter sequence show up at the beginning of a few reads. 
   Also the -A and -B arguments should be as they show up in your data, 
   SeqPrep searches directly for these sequences without doing reverse 
   complementing.
3. Check the forward and reverse and make sure that you have roughly the 
   same number of hits via a command to count hits like: 
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | wc -l
```{r setting_seq_adapters_based_on_platform, cache=TRUE}
fwdAdapHiSeq    <- "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"  # HiSeq, Genome Quebec
revAdapHiSeq    <- "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"  # HiSeq, Genome Quebec

# Notice that the adapter sequences we chose when processing the MiSeq reads
# is from the same region we are choosing for our HiSeq reads, only shorter:
fwdAdapMiSeq <- "AGATCGGAAGAGCACAC"   # MiSeq
revAdapMiSeq <- "AGATCGGAAGAGCGTCGT"  # MiSeq

fwdAdapIonT  <- "CCATCTCATCCCTGCGTGTCTCCGACTCAG" # "A" adapter sequence for IonTorrent
revAdapIonT  <- "CCTCTCTATGGGCAGTCGGTGAT"        # "trP1" adapter sequence for IonTorrent

if(platform == 1){
    fwdAdap <- fwdAdapMiSeq
    revAdap <- revAdapMiSeq
    print('Your sequencing platform was set to the Illumina MiSeq')} else if 
(platform == 2){
    fwdAdap <- fwdAdapHiSeq
    revAdap <- revAdapHiSeq
    print('Your sequencing platform was set to the Illumina HiSeq')} else if
(platform == 3){
    fwdAdap <- fwdAdapIonT
    revAdap <- revAdapIonT
    print('Your sequencing platform was set to the Ion Torrent')} else {
        rm(fwdAdap, revAdap)
        print('You either didn\'t specify a valid sequence platform, or none was provided')
    }
fwdAdap
revAdap
```

The user does not alter the variables below. 
```{r settingToQsubWithinRStudio, cache=TRUE}
Sys.setenv(PATH=paste('/opt/gridengine/bin/linux-x64',Sys.getenv('PATH'),sep= ':'))
```


The following chunk will integrate the user-defined variables from the previous chunk into the script.
```{r creating_dir_for_analysis, cache=TRUE}
# Create the analysis directory:
dir.create(paste(sharedPath, analysis, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

# Set the path to the analysis directory:
sharedPathAn <- paste(sharedPath, analysis, sep="")

# Create fastq directory in sharedPath folder based on "seqDataDir":
dir.create(paste(sharedPathAn, seqDataDir, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

# Set the path the fastq directory:
pathFastq <- paste(sharedPathAn, seqDataDir, "/", sep = "")
```

Path to the biocluster-installed tools:
```{r biocluster_tools_paths, cache=TRUE}
tophat2Path      <- "/opt/bio/tophat/bin/tophat2"
bowtie2BuildPath <- "/opt/bio/bowtie2/bowtie2-build"
starPath         <- "/opt/bio/STAR/STAR"
htseqCountPath   <- "/opt/bio/HTSeq/bin/htseq-count"
prinSeqPath      <- "/opt/bio/prinseq-lite/prinseq-lite"
prinSeqGraphPath <- "/opt/bio/prinseq-lite/prinseq-graphs"
samtools1Path    <- "/opt/bio/samtools1/bin/samtools1"
seqPrepPath      <- "/opt/bio/SeqPrep/SeqPrep"
```

Bowtie:
Creating Bowtie reference index from the fasta file: Not done for Lachnellula willkommii
```{r bowind eval = FALSE, echo = FALSE, include = FALSE, cache=TRUE}
bowind <- "lachwiiRef"

cmd    <- paste(bowtie2BuildPath, 
                " -f ", pyuuRefPath,
                " ", paste(referencesPath, bowind, sep = ""),
                sep = "")
cmd
#system(cmd)
```

Below the metadata file specified by the user is copied into the analysis folder and read into R:
```{r copy_metadata_to_analysis_dir_and_read, cache=TRUE}
cmd      <- paste("cp ", metadataPath, " ", sharedPathAn, sep = "")
system(cmd)
metadata <-  read.table(paste(sharedPathAn, metadataFileAlternate, sep = ""),
                        sep          = ",",
                        header       = TRUE,
                        comment.char = "", 
                        quote        = "",
                        as.is        = TRUE)
if(libraryLayout == 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, "_", 
                                    metadata$ReadDirection, ".fastq", sep = "")
} else if
(libraryLayout != 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, ".fastq", sep = "")
}
```

This function will delete qsub temp files that are the sub.e* outputs (error outputs)
```{r}
X <- function(path, prefixSub) {
  system(paste("find ", path, prefixSub, "/", prefixSub, "*", ".sub.e", "*", " -delete ", sep = ""))
}
```

Copy and gunzip files:
```{r copyRaw_gunzip, cache=TRUE}
# Copy all files using multiple processors (this is a lot faster than the above)
# cmd <- with(metadata, paste("cp ", 
#                 FastqFilePath," ", 
#                 sharedPathAn, seqDataDir, "/", basename(FastqFilePath),"\n",
#                 " gunzip ", 
#                 sharedPathAn, seqDataDir, "/", basename(metadata$FastqFilePath),
#                 sep=""))
# OR

#If you want to rename the files that you are copying over, do the following.
#It is based on what you put under BaseCallsName in your adapted metadata csv.
cmd <- with(metadata, paste("cp ", 
                FastqFilePath," ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".gz","\n",
                " gunzip ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".gz",
                sep=""))

# Generate qsub and bash files to complete the commands above:
prefix <- "A_copy_unzip" 
suffix <- ".sub"
MakeQsubs(cmd, prefix, suffix)
```

Clean-up step:
Remove the output files while keeping the qsub and bash file:
```{r, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the raw fastq files to the metadata table
```{r, cache=TRUE}
if(libraryLayout == 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, "_", 
                                   metadata$ReadDirection, ".fastq", sep = "")}
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, ".fastq", sep = "")
    }
}
```
The following will create a metadata table based on the library layout - paired-end or single reads.
Read pairs will be collapsed to one row per pair.
```{r, cache=TRUE}
library("reshape2")
if(libraryLayout == 2){
    metadataRawPairs <- dcast(data = metadata, LibraryName 
                              ~ ReadDirection, value.var = "BaseCallsName", FUN = c)
    metadataRawPairs$ShortName <- paste(metadataRawPairs$LibraryName)
    metadataRaw <- metadataRawPairs} else if
(libraryLayout != 2){
    metadata$ShortName <- paste(metadata$LibraryName)
    metadataRaw <- metadata} else {
        cat(c("Error: Either an incorrect number was entered for library", "\n",
              "layout (single reads = 1 and paired-end reads = 2), or no selection was", "\n",
              "specified. The default will be to consider reads single.", sep = ""))
        metadata$ShortName <- paste(metadata$LibraryName)
        metadataRaw <- metadata
        }
# We can get more specific if we want, such as when there are many samples and/or a time-course:

# metadataRawPairs$ShortName <- paste(metadataRawPairs$Condition, 
#                                     metadataRawPairs$TimePoint, 
#                                     metadataRawPairs$RNASeq_Replicate, sep = ".")
```

Looking at our raw data:
Ensure that if reads are paired-end, that they are correctly paired and ordered between read 1 and
read 2 fastq files.
```{r, cache=TRUE}
# Run FastqPairedEndValidator for the first time on the raw read pairs:
if(libraryLayout == 2){
    prefix <- "B_Validator"
    cmd <-  with (metadataRaw, paste(fastqPEValidatorPath,
                                     " ", pathFastq, R1, " ", pathFastq, R2, sep = ""))
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
        cat(c("Fastq pairend end validator will not be used because you did not specify that", "\n",
              "your reads are paired end", sep = ""))
        }
#system("qstat")
```

If reads were paired-end, and the Fastq Paired-End validator was run, the output of each pair will
be displayed on the console:
```{r, echo=FALSE, cache=TRUE}
if(libraryLayout == 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
        system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".o*", sep = ""))
        cat("\n")}} else if
(libraryLayout != 2){
    cat(c("The fastq pairend end validator was not used because you specified that your", "\n",
              "reads are not paired end", sep = ""))
        }
```
To remove the output files after you are done:
```{r, echo=FALSE, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Look at the raw fastq graphs prior to adapter removal, QA, and other processing
using PrinSeq graph reports of raw reads, 
Step 1: .gd file generation:
```{r, echo=FALSE, cache=TRUE}
prefix <- "C_PrinSeq_rawGraphs"
if(libraryLayout == 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$R1, prefix,
                                 "rawGraphs", metadataRaw$R2)
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$RawFastq, prefix, "rawGraphs")
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
}
```

Add the name of the raw graphs .gd files to the 
metadata table:
```{r echo = FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$RawGraphName <- paste(metadataRaw$LibraryName, ".rawGraphs.gd", sep = "") 
}
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

PrinSeq graph reports of raw reads. 
Step 2: html file generation:
```{r echo = FALSE, cache = TRUE}
prefix2 <- "C2_PrinSeqRawGraphs"
cmd <- MakePrinSeqHTML(metadataRaw, prefix, metadataRaw$RawGraphName)
suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```
*** Over here!!! Error - graphs html not run because of JSON.pm dependency error!
Work-around: uploaded the .gd file on the PrinSeq web server to generate the html files:
http://edwards.sdsu.edu/cgi-bin/prinseq/prinseq.cgi?report=1 
You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Merging and adapter removal before processing:
Adapter detection:
```{r echo = FALSE, cache = TRUE}
if(libraryLayout == 2){
for (k in 1:nrow(metadataRaw)) {
  cat(c(k, metadataRaw$R1[k]))
  system(paste("cat ", pathFastq, metadataRaw$R1[k], 
               " | head -n 1000000 | grep '", 
               fwdAdap, "' | wc -l ", sep = ""))
  cat("\n")
  }
    for (k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R2[k]))
      system(paste("cat ", pathFastq, metadataRaw$R2[k], 
                   " | head -n 1000000 | grep '", 
                   revAdap, "' | wc -l ", sep = ""))
      cat("\n")
      } 
    } else if
(libraryLayout != 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k]))
        system(paste("cat ", pathFastq, metadataRaw$RawFastq[k],
                     " | head -n 1000000 | grep '",
                     fwdAdap, "' | wc -l ", sep = ""))
        cat("\n")
    }
}
```

*** Over here!!!! 
Adapter removal:
```{r}
prefix <- "D_SeqPrep_adapter_Removal"
if(libraryLayout == 2){
    cmd <- with(metadataRaw, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, R1,
                  " -r ", pathFastq, R2,
                  " -1 ", pathFastq, LibraryName, ".adapRem.R1.fastq.gz",
                  " -2 ", pathFastq, LibraryName, ".adapRem.R2.fastq.gz",
                  " -A ", fwdAdap,
                  " -B ", revAdap,
                  " -s ", pathFastq, paste(LibraryName, ".adapRemMerged.fastq.gz", sep = ""),
                  sep = ""))} else if 
(libraryLayout != 2){
    cmd <- with(metadataRaw, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, RawFastq,
                  " -1 ", pathFastq, LibraryName, ".adapRem.fastq.gz",
                  " -A ", fwdAdap,
                  sep = ""))
}
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

To show the output of each pair on the console in Rstudio:
```{r}
if(libraryLayout == 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$RawFastq[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```


Pre-Processing of Raw Reads using PrinSeq::

PrinSeq Processing of Raw reads:
PrinSeq Options Setting:
```{r}
nmax           <- 1
trimLeft       <- 15
trimRight      <- 10
trimTailLeft   <- 5   # Only for RNA-Seq - There should be no poly-tails in DNA
trimTailRight  <- 5  # Only for RNA-Seq - There should be no poly-tails in DNA
trimQualWindow <- 7 # To make this less conservative, increase from 3 to 7
trimQualType   <- "mean"
trimQualRight  <- 10 # Consider reducing from 30 to 10 initially
trimQualLeft   <- 10  # Consider reducing from 30 to 10 initially
trimQualRule   <- "lt"
lcMethod       <- "dust"
lcThreshold    <- 7
outGood        <- "processed_merged"    # Define by user
outBad         <- "null"
minLen         <- 100        # Consider reducing from 100 to 60? initially
```

For the pre-processing with PrinSeq we have three steps, with three 
sets of qsubs each:

1. Processing input raw reads with the PrinSeq trim and fitlering options
2. Generating graph files of the processed reads
3. Generating html files using the graph files to visualize the outputs

For each set of qsubs, the .log, .gd, and .html outputs are sent to the 
first folder that also has the first stage qsub and bash files. 
The processed reads are output to the pathfastq folder.

PrinSeq Processing of merged reads:
First stage of quality pre-processing with PrinSeq:

1-1. 
Filter raw.fastq output from SeqPrep by quality: Note, with 
merging with SeqPrep during adapter removal, the reads are already 
filtered and are of high quality as only the high quality reads can 
be merged.
```{r}
prefix <- "C_PrinSeqGraphQualTrim"

# I revised the function, so look to RNASeq script for how to make this work.
cmd = with(metadata, 
           paste(prinSeqPath,
                 " -fastq ",             pathFastq,  RawFastq,
                 " -trim_qual_window ",  trimQualWindow,
                 " -trim_qual_type ",    trimQualType, 
                 " -trim_qual_right ",   trimQualRight,
                 " -trim_qual_rule ",    trimQualRule,
                 " -out_good ",          paste(pathFastq, LibraryName,
                                               ".2processedRaw",
                                              sep = ""),
                 " -out_bad  ",          outBad,
                 " -verbose ",
                 " -no_qual_header ",
                 " -log ",               sharedPathAn, prefix, "/", 
                                         LibraryName, ".2processedRaw.log",
                 sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Add name of quality-filtered reads .fastq files to the metadata 
tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1Fastq <- paste(metadata$LibraryName,
                                    ".2processedRaw.fastq",
                                    sep = "") 
}
```
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Gzip the fastq reads that were INPUT to the PrinSeq processing in step 1-1, 
we won't need them and the next step in 1-2 will be using the OUTPUT processed 
reads. 
```{r}
prefix <- "C_gzipRaw"
cmd <- with(metadata, paste("gzip ",
                            pathFastq,
                            metadata$RawFastq,
                            sep=""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

1-2.
Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix <- "C_PrinSeqGraphQualTrim"
prefix2 <- "C2_PrinSeqGraph"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed1Fastq,
                             prefix, "2processedRaw")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadata)){
    cat(c(k, metadata$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Add name of quality-filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1GraphName <- paste(metadata$LibraryName,
                                        ".2processedRaw.gd",
                                        sep = "") 
}
```

1-3.
Problem with a JSON.pm dependency - therefore go to the online server to get html from the .gd file:
http://edwards.sdsu.edu/cgi-bin/prinseq/prinseq.cgi?report=1
PrinSeq graph reports of first-stage html file generation:
**Instead of putting in the filename manually, refer to metadata for it.
```{r}
prefix3 <- "C3_PrinSeqHtml"
cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed1GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

Second stage of quality pre-processing with PrinSeq:
Trim left and right, and Poly-A/T tail removal, round 1
(Only for RNA-seq, not genome sequencing)
2-1.
```{r}
prefix <- "D_PrinSeqTrimLRPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
                  " -out_good ",        paste(pathFastq, LibraryName, 
                                              ".3processed", sep = ""),
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".3processed.log", 
                                              sep = ""),
                  sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

(Only for RNA-seq, not genome sequencing)
Add name of Poly-A/T, left and right trimmed reads .fastq files to the 
metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2Fastq <- paste(metadata$LibraryName, 
                                    ".3processed.fastq",
                                    sep = "") 
}
```


2-2.
(Only for RNA-seq, not genome sequencing)
Generate PrinSeq graph files (.gd) for the fastq generated previously:
This works, but the temp files are large - so beware of disc usage.
```{r}
prefix2 <- "D2_PrinSeqGraphTrimLRPolyAT"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed2Fastq,
                             prefix, "3processed")

# prefix5 <- "D5_PrinSeqGraphTrimLRPolyAT"
# cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed2Fastq,
#                              prefix, "3processed")


suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```


Gzip the fastq reads that were output to the PrinSeq processing in step 2-1, 
input reads stayed compressed - no need to compress those. Had to stop this
testing of submitting by qsub.
```{r}
prefix3 <- "C_gzipProcessed"

cmd <- with(metadata, paste("gzip ", 
                            pathFastq, 
                           #  metadata$processed2Fastq,
                            metadata$processed1Fastq,
                            sep = ""))

# sapply(cmd, function(x) system(x))

# suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

(Only for RNA-seq, not genome sequencing)
Add name of trimmedLR/PolyAT reads .gd files to the metadata tabel: (Done)
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2GraphName <- paste(metadata$LibraryName,
                                        ".3processed.gd",
                                        sep = "") 
}
```


2-3.
(Only for RNA-seq, not genome sequencing)
PrinSeq graph reports of second-stage html file generation:
```{r}
prefix4 <- "D4_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed2GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix4, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix4)
```

(Only for RNA-seq, not genome sequencing)
Third stage of quality pre-processing with PrinSeq:
Poly-A/T tail removal, round 2:
Repeat poly tails trimming, because after trimming ends that had AAAAATTTTT 
that has been trimmed for the poly-T will still have the poly-A string.
3-1.
```{r}
prefix <- "E_PrinSeq2ndPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed2Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
#                   " -out_good ",        paste(pathFastq, LibraryName,
#                                               ".4processed", sep = ""),
                  " -out_good stdout ",
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".4processed.log", 
                                              sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".4processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

(Only for RNA-seq, not genome sequencing)
Add name of 2nd polyAT trimmed reads .fastq files to the 
metadataAdapRM tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed3Fastq <- paste(metadata$LibraryName, ".4processed.fastq",
                                    sep = "") 
}
```

3-2.
(Only for RNA-seq, not genome sequencing)
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "E2_PrinSeq2ndTrimPolyATgraphs"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed3Fastq,
                             prefix, "4processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

(Only for RNA-seq, not genome sequencing)
Add name of second trimmed PolyAT reads .gd files to the metadata tabel:
```{r}

for(k in 1:nrow(metadata)){
  metadata$processed3GraphName <- paste(metadata$LibraryName, 
                                        ".4processed.gd", sep = "") 
}
```


3-3.
(Only for RNA-seq, not genome sequencing)
PrinSeq graph reports of third-stage html file generation:
```{r}
prefix3 <- "E3_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed3GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

(Only for RNA-seq, not genome sequencing)
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```


Fourth and LAST stage of quality pre-processing with PrinSeq:
Filtering of reads by complexity (DUST) and minimum length

4-1.
```{r}
prefix <- "D_PrinSeqDustMinLen"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -min_len ",        minLen,
                  " -lc_method ",      lcMethod,
                  " -lc_threshold ",   lcThreshold,
                  " -out_good stdout ",
                  " -out_bad  ",       outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",            paste(sharedPathAn, prefix, "/", 
                                             LibraryName, ".3processed.log", 
                                             sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".3processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```


```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2Fastq <- paste(metadata$LibraryName, ".3processed.fastq",
                                    sep = "") 
}
for(k in 1:nrow(metadata)){
  metadata$finalProcessedPath <- paste(pathFastq, "/", metadata$LibraryName, ".3processed.fastq",
                                    sep = "") 
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

4-2
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "D2_PrinSeqDustMinLength"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed2Fastq,
                             prefix, "3processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

Add name of Dust and MinLen filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2GraphName <- paste(metadata$LibraryName, ".3processed.gd",
                                        sep = "") 
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
# RemoveQsubTempFiles(sharedPathAn, prefix)
```

Assembling de novo:
ABySS
IDBA-UD (can't get it to work, tried with -l option for long reads)
SOAPdenovo(SOAP) (we won't use this - it's for short reads)
SPAdes
Newbler
SparseAssembler(Sparse)
Velvet (we won't use this - it's for short reads)
```{r}
pathkmerGenie <- "/home/CFIA-ACIA/girouxeml/prog/kmergenie-1.7044/kmergenie"
pathABYSS <- "/opt/bio/abyss/bin/ABYSS"
pathIDBAud <- "/opt/bio/idba/bin/idba_ud"
pathSOAPdenovo <- "opt/bio/SOAPdenovo2/SOAPdenovo-63mer"
pathVelvet <- "/opt/bio/velvet/"
```

Gather fasta data required for all assemblies:
```{r}
library(data.table)
metadata_dt <- as.data.table(metadata)
setkey(metadata_dt, ScientificName, LibraryName, processed2Fastq, finalProcessedPath)

head(metadata_dt)
key(metadata_dt)
metadataAssembly <- metadata_dt[, c("ScientificName", "LibraryName", "processed2Fastq", "finalProcessedPath"), with=FALSE]
metadataAssemblyLawii <- data.table("ScientificName"=c("Lachnellula_willkommii"),
                                    "LibraryName"=c("Lawi_IonT_Debbie_1"),
                                    "processed2Fastq"=c("wholeGen_Lawii.5processed.fastq"),
                                    "finalProcessedPath"= c(paste(sharedPath,
                                                            "Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/wholeGen_Lawii.5processed.fastq",
                                                            sep = "")))
metadataAssembly <- rbind(metadataAssembly, metadataAssemblyLawii)

```

```{r}
prefix <- "kmerGenie"

cmd <- paste(pathABYSS, " --help", sep = "")
cmd <- paste(pathkmerGenie, " --help", sep = "")
system(cmd)

cmd <- with(metadataAssembly,paste(pathkmerGenie, " ", finalProcessedPath, ".gz", 
                           " -o ", LibraryName, sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the best k-mer values identified by kmergenie for each genome and the predicted assembly size:
```{r}
pathKmerGenieDat <- paste(sharedPath, analysis, "kmerGenie/", sep = "")

for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$kmerGenieDat <- paste(metadataAssembly$LibraryName, ".dat", sep = "") 
  metadataAssembly$kmerGenieDatPath <- paste(pathKmerGenieDat, metadataAssembly$kmerGenieDat, sep = "")
}

for(i in 1:nrow(metadataAssembly)){
    kmerdatTmp <- fread(metadataAssembly$kmerGenieDatPath[i], sep = "auto", header = TRUE)
    setkey(kmerdatTmp, genomic.kmers)
    key(kmerdatTmp)
    maxGenomicKmers <- max(kmerdatTmp$genomic.kmers)
    metadataAssembly$BestKmerGenie[i] <- kmerdatTmp[.(maxGenomicKmers), .(k)]
}
```

Assemble with ABySS and the kmer best from kmergenie:
```{r}
cmd <- paste(pathABYSS, " --help", sep = "")
system(cmd)

prefix <- "Assembly_ABySS"

for(i in 1:nrow(metadataAssembly)){
cmd <- with(metadataAssembly, paste(pathABYSS, " -k ", metadataAssembly$BestKmerGenie, 
                                    " ", paste(metadataAssembly$finalProcessedPath, ".gz", sep = ""), 
                                    " -o ", paste("kmer_", metadataAssembly$BestKmerGenie, "_", LibraryName, ".fastq", sep = ""),
                                    " --coverage-hist ", paste(sharedPath, analysis, prefix, "/",
                                                               "kmer_", metadataAssembly$BestKmerGenie, "_",
                                                               LibraryName, ".hist", sep = ""),
                                    " -v ",
                                    " -q 10 ",
                           sep = ""))
}


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Add the names of the genome fastq files assembled with ABySS, and their paths to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$ABySSfastq <- paste("kmer_", metadataAssembly$BestKmerGenie, "_", metadataAssembly$LibraryName, ".fastq", sep = "")
  metadataAssembly$ABySSfastqPath <- paste(sharedPath, analysis, "Assembly_ABySS/", metadataAssembly$ABySSfastq, sep = "")
}
```

Creating a blast database using previous Lachnellula willkommii genome assembly done with Newbler, 
and then blasting the ABySS assembly fastqs for all the genomes against it:
```{r}
# To make the database:

 # makeblastdb -in /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/Assembly1_NewblerAllGCrange/454AllContigs.fna -input_type fasta -dbtype nucl -hash_index -parse_seqids

# To Blast against it:

# blastn -query /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_species_GenomeAn_IonTorrent_2017/Assembly_ABySS/kmer_81_Lawi_IonT_Debbie_1.fastq -db /home/CFIA-ACIA/girouxeml/PIRL_working_directory/Lachnellula_willkommii_GenomeAn/IonTorrent_data_Debbie1/Assembly1_NewblerAllGCrange/454AllContigs.fna -out ./Lawii_454AllContigs.blastn -outfmt '6 qseqid sseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore' -num_threads $(nproc) -max_target_seqs 1

prefix <- "LawiiMitodbBlast"

for(k in 1:nrow(metadataAssembly)){
    cmd <- paste("blastn ", 
                 "-query ", metadataAssembly$NewblerFnaPath,
                 " -db ", paste(sharedPath, "data/Lachnellula_willkommii/Final_Sequences/Mitochondrial_from_contig00001.fasta", sep = ""),
                 " -out ", paste("./", metadataAssembly$LibraryName, "_454AllContigs.blastn", sep = ""),
                 " -outfmt ", "'6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' -num_threads $(nproc) -max_target_seqs 1",
                 sep = "")
}
suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Get the ABySS assembly contiguity metrics
```{r}
pathABYSSfac <- "/opt/bio/abyss/bin/abyss-fac"

prefix <- "Assembly_ABySS-fac"

for(i in 1:nrow(metadataAssembly)){
cmd <- with(metadataAssembly, paste(pathABYSSfac, " ", metadataAssembly$ABySSfastqPath, 
                                    " -v ", sep = ""))
}

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

To remove the error output files after you are done: (we need the sub.o* to gather the stats)
```{r}
X(sharedPathAn, prefix)
```

ABySS Contig stats output format:

Column	Description
n	    Total number of sequences
n:500	Number of sequences at least 500 bp
L50	    Number of sequences at least the N50 size
LG50	Number of sequences at least the NG50 size
NG50	Half the genome is in sequences of the NG50 size or larger
min	    The size of the smallest sequence
N80	    At least 80% of the assembly is in sequences of the N80 size or larger
N50	    At least half the assembly is in sequences of the N50 size or larger
N20	    At least 20% of the assembly is in sequences of the N20 size or larger
E-size	The sum of the square of the sequence sizes divided by the assembly size
max	    The size of the largest sequence
sum	    The sum of the sequence sizes
name	The file name of the assembly
```{r}
library(reshape2)
pathABySS_fac_results <- paste(sharedPath, analysis, prefix, "/", sep = "")
list.files(pathABySS_fac_results, Sys.glob("*.sub.o*"))
listABySS_fac_res <- Sys.glob(file.path(pathABySS_fac_results, "*.sub.o*"))


i <- 1
for(i in 1:length(listABySS_fac_res)){
    test[[i]] <- fread(listABySS_fac_res[i], sep = "auto", header = TRUE)
    test[[i]]$ABySSfastq <- basename(test[[i]]$name)
    print(nrow(test[[i]]))
}

summary(test)
View(test[[1]])

library(data.table)
testList <- list(test[[1]], test[[2]], test[[3]], test[[4]], test[[5]], test[[6]], test[[7]])
testAll <- Reduce(function(x, y) merge(x, y, all=TRUE), testList)

write.table(testAll, file = file.path(paste(sharedPathAn, analysis, "ABySS_Assembly_Contiguity_Stats_all_genomes.csv", sep = "")),
            append = FALSE,
            quote  = FALSE,
            row.names = FALSE,
            sep = ",",
            col.names = TRUE)
```

Assembling with Newbler
Must first gunzip the fastq as Newbler can't use compressed files!
```{r}
prefix <- "GunZipForNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gunzip ", paste(metadataAssembly$finalProcessedPath, ".gz", sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

```{r}
newblerPath <- "/opt/bio/454/bin/newbler"
runAssPath  <- "/opt/bio/454/bin/runAssembly"

prefix <- "Assembly_Newbler"
prefix2 <- "Assembly_NewblerQsub_Lari_only" # for re-running Newbler on L. arida, there was an error on first run try.
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(runAssPath, 
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, sep = ""),
                      " ",    paste(metadataAssembly$finalProcessedPath, sep = ""), 
                      sep = ""))
}
cmd[1] # cmd to re-run Lari only due to previous run crash   
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
# MakeQsubs(cmd[1], prefix2, suffix) # For re-running Lari due to previous run crash.
```
* Not done yet for the repeat Lari qsub assembly
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the assembled contigs paths from Newbler to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$NewblerFnaPath <- paste(sharedPath, analysis, "Assembly_Newbler/", metadataAssembly$LibraryName, "/454AllContigs.fna", sep = "")
}
```

* Not done yet because Lari still assembling
Must first gzip the fastq after Newbler assembly to save space!
```{r}
prefix <- "GZipAfterNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gzip ", paste(metadataAssembly$finalProcessedPath, sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

Assembling genomes with SPades:
```{r}
pathSpades <- "/home/CFIA-ACIA/girouxeml/prog/SPAdes-3.10.1-Linux/bin/spades.py"
prefix <- "Assembly_SPAdesMultipleKmers"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(pathSpades, " ", 
                      " --iontorrent ",
                      " -k ", "21,33,45,57,69,81,93,105,117,127",
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, sep = ""),
                      " -s ", metadataAssembly$finalProcessedPath,
                      sep = "")
    )
}
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To delete the qsub outputs errors only, in case the sub.o* have info we need to gather.
```{r}
X(sharedPathAn, prefix)
```

Add the assembled contigs paths from SPAdes to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$SPAdesFastaPath <- paste(sharedPath, analysis, "Assembly_SPAdesMultipleKmers/", 
                                          metadataAssembly$LibraryName, "/scaffolds.fasta", sep = "")
}
```
* Not done for Lari yet
quast to evaluate assemblies
```{r}
pathQuast <- "/opt/bio/quast/quast.py"

prefix <- "Assembly_Assessment_Quast"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(pathQuast, " ", 
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, "/", sep = ""),
                      #" -l ", metadataAssembly$LibraryName,
                      " -e ", # " -f",
                      " ", metadataAssembly$ABySSfastqPath, 
                      " ", metadataAssembly$SPAdesFastaPath, 
                      " ", metadataAssembly$NewblerFnaPath,
                      sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Usage: python /opt/bio/quast/quast.py [options] <files_with_contigs>

Options:
-o  --output-dir  <dirname>   Directory to store all result files [default: quast_results/results_<datetime>]
-R                <filename>  Reference genome file
-G  --genes       <filename>  File with gene coordiantes in the reference
-O  --operons     <filename>  File with operon coordiantes in the reference
    --min-contig  <int>       Lower threshold for contig length [default: 500]

Advanced options:
-T  --threads      <int>              Maximum number of threads [default: number of CPUs]
-l  --labels "label, label, ..."      Names of assemblies to use in reports, comma-separated. If contain spaces, use quotes
-L                                    Take assembly names from their parent directory names
-f  --gene-finding                    Predict genes (with GeneMarkS from prokaryotes (default), GlimmerHMM
                                      for eukaryotes (--eukaryote), or MetaGeneMark for metagenomes (--meta)
-S  --gene-thresholds                 Comma-separated list of threshold lengths of genes to search with Gene Finding module
                                      [default is 0,300,1500,3000]
-e  --eukaryote                       Genome is eukaryotic
-m  --meta                            Metagenomic assembly. Use MetaGeneMark for gene prediction.
    --est-ref-size <int>              Estimated reference size (for computing NGx metrics without a reference)
    --gage                            Use GAGE (results are in gage_report.txt)
-t  --contig-thresholds               Comma-separated list of contig length thresholds [default: 0,1000]
-s  --scaffolds                       Assemblies are scaffolds, split them and add contigs to the comparison
-u  --use-all-alignments              Compute genome fraction, # genes, # operons in the v.1.0-1.3 style.
                                      By default, QUAST filters Nucmer's alignments to keep only best ones
-a  --ambiguity-usage <none|one|all>  Use none, one, or all alignments of a contig with multiple equally
                                      good alignments [default is one]
-n  --strict-NA                       Break contigs in any misassembly event when compute NAx and NGAx
                                      By default, QUAST breaks contigs only by extensive misassemblies (not local ones)

    --test                            Run QUAST on the data from the test_data folder, output to test_output
-h  --help                            Print this message


Doesn't work:
```{r}
cmd <- paste(pathIDBAud, " --help", sep = "")
system(cmd)

prefix8 <- "IDBAudAssembly"

mink <- 21
maxk <- 96
stepk <- 10


cmd <- with(metadataAssembly, paste(pathIDBAud,
                                    " -o ", paste(sharedPath, analysis, prefix8, "/", sep = ""),
                                    " -r ", paste(finalProcessedPath, ".gz", sep = ""),
                                    " -l ",
                                    " --mink ", mink,
                                    " --maxk ", maxk,
                                    " --step ", stepk, sep = ""
                                    ))
MakeQsubs(cmd, prefix8, suffix)
```


Allowed Options:
  -o, --out arg (=out)                   output directory
  -r, --read arg                         fasta read file (<=300)
      --read_level_2 arg                 paired-end reads fasta for second level scaffolds
      --read_level_3 arg                 paired-end reads fasta for third level scaffolds
      --read_level_4 arg                 paired-end reads fasta for fourth level scaffolds
      --read_level_5 arg                 paired-end reads fasta for fifth level scaffolds
  -l, --long_read arg                    fasta long read file (>300)
      --mink arg (=20)                   minimum k value (<=312)
      --maxk arg (=100)                  maximum k value (<=312)
      --step arg (=20)                   increment of k-mer of each iteration
      --inner_mink arg (=10)             inner minimum k value
      --inner_step arg (=5)              inner increment of k-mer
      --prefix arg (=3)                  prefix length used to build sub k-mer table
      --min_count arg (=2)               minimum multiplicity for filtering k-mer when building the graph
      --min_support arg (=1)             minimum supoort in each iteration
      --num_threads arg (=0)             number of threads
      --seed_kmer arg (=30)              seed kmer size for alignment
      --min_contig arg (=200)            minimum size of contig
      --similar arg (=0.95)              similarity for alignment
      --max_mismatch arg (=3)            max mismatch of error correction
      --min_pairs arg (=3)               minimum number of pairs
      --no_bubble                        do not merge bubble
      --no_local                         do not use local assembly
      --no_coverage                      do not iterate on coverage
      --no_correct                       do not do correction
      --pre_correction                   perform pre-correction before assembly

* Not Done for Lari yet
```{r}
library(Biostrings)
i <- 1
for(i in 2:nrow(metadataAssembly)){
    tempFasta <- readDNAStringSet(metadataAssembly$NewblerFnaPath[i], format = "fasta")
    tempContig1 <- tempFasta[1]
    names(tempContig1) = sub(" .*", "", names(tempContig1))
    names(tempContig1) = paste(names(tempContig1), "_", metadataAssembly$LibraryName[i], sep = "")
    writeXStringSet(tempContig1, 
                    file = paste(sharedPathAn, "Newbler_Contig1_all_Lachnellula.fasta", sep = ""), 
                    append = TRUE, 
                    format = "fasta") 
}

pathContig1 <- paste(sharedPathAn, "Newbler_Contig1_all_Lachnellula.fasta", sep = "")
for(i in 1:length(ID_fasta_files)){
  cmd <- paste("/opt/bio/mafft/bin/mafft --reorder --quiet '",  pathContig1, "' > ", 
             pathContig1, "_mafft_aligned.fasta", sep = "")
  system(cmd)
}
```

* Done
This is to see about contaminating sequence profile using Kraken, with Krona for visualization.
```{r}
pathKraken <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken"
krakenDB <- "/home/CFIA-ACIA/girouxeml/Kraken_first_DataBase"

dir.create(paste(sharedPathAn, "krakenContaminationTesting", sep = ""), showWarnings=TRUE, recursive=FALSE)
pathKrakenTests <- paste(sharedPathAn, "krakenContaminationTesting/", sep = "")

prefix <- "kraken_testingQsubs"
cmd <- with(metadataAssembly,
            paste(pathKraken,
                  " --preload ",
                  " --db ", krakenDB,
                  " --fastq-input",
                  " --threads 12 ",
                  " --output ", paste(pathKrakenTests, "krakenTesting_", 
                                      metadataAssembly$LibraryName, ".output", sep = ""),
                  " ", paste(metadataAssembly$finalProcessedPath, sep = ""),
                  sep = ""))

# Note, if there are a lot of qsubs to run, some may terminate due to lack of
# available memory to run on the cluster. You can see which ones didn't run 
# by cd into the directory with the qsubs, and on the command line do:
# $  find . -type f -exec grep -H 'Cannot allocate memory' {} \;
# You can then run these separately after the others are complete.
# So far, one of the 6, L. ari will need to be resubmitted because of this.

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KrakenOutput <- paste("krakenTesting_", metadataAssembly$LibraryName, ".output", sep = "") 
}
```
* Done
For users who want the full taxonomic name associated with each input sequence, 
use kraken-translate to produce two different output formats for classified sequences. 
The script operates on the output of kraken, like so: 
kraken-translate --db $DBNAME sequences.kraken > sequences.labels
```{r}

prefix <- "krakenTranslateQsubs"
pathKrakenTranslate <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken-translate"

cmd <- with(metadataAssembly,
            paste(pathKrakenTranslate,
                  " --db ", krakenDB,
                  " ", paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", paste(pathKrakenTests, "krakenTesting_", metadataAssembly$LibraryName,
                               ".labels", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KrakenOutputLabels <- paste("krakenTesting_", metadataAssembly$LibraryName, ".labels", sep = "") 
}
```

* Done
After blasting our sequences against our Kraken database, we tabulate the results using the following:
```{r}
prefix <- "krakenReportQsubs"
pathKrakenResults <- "/home/CFIA-ACIA/girouxeml/prog/kraken/kraken-report"

cmd <- with(metadataAssembly,
            paste(pathKrakenResults,
                  " --db ", krakenDB,
                  " ", paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", paste(pathKrakenTests, "krakenTesting_", metadataAssembly$LibraryName,
                               ".report", sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```

* Done
To visualize the kraken data, we can use krona:
```{r}
prefix <- "KrakenToKronaInFormatQsub-outputIn"
pathKronaImportTax <- "/home/CFIA-ACIA/girouxeml/prog/bin/ktImportTaxonomy"

cmd <- with(metadataAssembly,
            paste("cut -f2,3 ", 
                  paste(pathKrakenTests, metadataAssembly$KrakenOutput, sep = ""),
                  " > ", 
                  paste(pathKrakenTests, "krona_outputIn_", metadataAssembly$LibraryName, ".in", sep = ""),
                  sep = ""))
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```
* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```
* Done
To add the kraken output files to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$KronaIn <- paste("krona_outputIn_", metadataAssembly$LibraryName, ".in", sep = "") 
}
```

* Done
Passing in to krona:
```{r}
prefix <- "kronaQsubs_OutputIn"
pathKronaImportTax <- "/home/CFIA-ACIA/girouxeml/prog/bin/ktImportTaxonomy"

cmd <- with(metadataAssembly,
            paste(pathKronaImportTax, " ", 
                  paste(pathKrakenTests, metadataAssembly$KronaIn, sep = ""),
                  " -o ", 
                  paste(pathKrakenTests, "krona_outputIn_", metadataAssembly$LibraryName, ".out.html", sep = ""),
                  sep = ""))
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

* Done
Clean-up step: Remove the output files while keeping the qsub and bash file:
```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
RemoveQsubTempFiles(sharedPathAn, prefix)
```



















