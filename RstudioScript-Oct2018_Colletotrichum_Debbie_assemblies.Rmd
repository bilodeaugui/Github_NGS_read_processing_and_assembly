# Installing the required packages for R:
# This is to be done in the R command line and not in R studio
#source("https://www.Bioconductor.org/biocLite.R")
#biocLite("BiocUpgrade")


Getting started in R: Set the working directory > setwd("~/") Check version installed
```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy = TRUE, fig.align='center')
```


This will help us when finding our files to source functions:
```{r sourcing_my_functions}
install.packages("rprojroot")
library(rprojroot)
# We specify ours is an RStudio project
# The root object contains a function that will help us locate our package r files
# regarless of our current working directory
root <- rprojroot::is_rstudio_project
scriptsPath <- root$make_fix_file(".")("R")
scripts  <- dir(root$find_file("R", path = root$find_file()))
scriptsl <- paste(scriptsPath, scripts, sep = "//")
lapply(scriptsl, source)
```

User: 
Define the path to the shared folder where the main working directory will be.
```{r setting_the_main_directory, cache=TRUE}
sharedPath <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory/"
```

User:
Specify the name and path of the csv file you would like to use for generation of the 
metadata file if not using the csv file generated by sequencing service:
*Note: I suggest saving the file in the references folder in the shared path. Getting more specific
and making a directory just for these tables is fine too - but the table will be copied to the new
directory for this analysis later in the script. It's just important to have a raw, untouched 
reference for this data kept in a place where you will remember and keep all the other ones you use.
```{r metadata_name_and_path, cache=TRUE}
metadataFileAlternate <- "colletotrichum_Debbie_metadata_IonT_2018.csv"
metadataPath <- paste(sharedPath, "References/", metadataFileAlternate, sep = "")
```

User:
Define the the folder in the shared folder that will hold the analyses of the 
time-course/dataset you will be working with. In our case, we have two different 
time-course experiments, Oosporogenesis and Oospore Conversion. Below we set 
which one the script will run analyses for. We also get the user to specify what 
the name of the directory that will hold the reads will be. In the case below, 
we are calling the sequencing data directory (seqDataDir) "MiSeq_data_Sci2" 
because sequencing of oospore conversion time-course reads was done on the 
in-house MiSeq and was the second run we had done on this instrument for the 
overall project. We also added Sci2 because the sequencing libraries were made 
on the SciClone robotics instrument, and also represent the second time we 
generated libraries on that instrument:
```{r analysis_and_sequence_directory, cache=TRUE}
analysis   <- "colletotrichum/"
seqDataDir <- "ionT_data"
```

User needs to specify the adapter sequences attached to the sequencing 
reads. This will depend on how the libraries were prepared. Specify which sequencing platform was 
used to generate the reads: 
1 - MiSeq
2 - HiSeq
3 - Ion Torrent

Also specify the library layout - paired-end or single reads (Illumina only):
1 - single
2 - paired-end
```{r sequencing_platform_used, cache=TRUE}
platform      <- 3
libraryLayout <- 1
```

User:
Specify the read-processing and quality assessment tool to be used.
1 - FastQC
2 - PrinSeq
```{r read_processing_tool, cache = TRUE}
readProc <- 2
```

User:
Specify which tool to use for assembly:
1 - Newbler (for 454 and Ion Torrent reads)
2 - SPADES (for Illumina reads, mainly)
```{r assembler, cache = TRUE}
assembler <- 1
```

User:
The following paths are to directories where the references, tools and general 
requirements are located, this depends on the directories actually having been 
put there:
```{r user_tools_and_references_dir, cache=TRUE}
toolsDirPath     <- paste(sharedPath, "tools/", sep = "")
referencesPath   <- paste(sharedPath, "References/", sep = "")
fastqPEValidatorPath <- paste(toolsDirPath, "FastqPairedEndValidator.pl", sep = "")
```

We prepared our libraries using the Mondrian and SciClone with library 
kits, instruments and kits by NuGen. NuGen kits are designed to work with 
Illumina sequencing platforms and generate libraries with the sequence 
structure:

5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 
   (N) 
   AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <- region to select as forward adapter
   XXXXXX 
   ATCTCGTATGCCGTCTTCTGCTTG 3'
   
3' TTACTATGCCGCTGGTGGCTCTAGATGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA 
   (N) 
   TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG <- region to select as reverse adapter
   XXXXXX 
   TAGAGCATACGGCAGAAGACGAAC 5'

Where each string of ‘X’ is the unique 4-, 6, or 8-base barcode from the 
L2 adaptor mix of the library construction system (where applicable) 
and (N) is the library insert.

We will need to remove any adapter sequences from our reads. We will
be doing this with SeqPrep. SeqPrep specifies that the user must first 
ensure the adapter sequences they choose are correct by doing a "grep"
on the reads first:

Before running SeqPrep make sure to check that the program's defaults 
are indeed the adapters you are looking for. Try copying the default 
forward adapter from this file and grep it against your reads doing a 
word count, also try the same with the reverse adapter with grep. You 
should see some hits. You can also try using (and validating with grep) 
-A GATCGGAAGAGCACACG -B AGATCGGAAGAGCGTCGT as parameters. To find a 
list of Illumina adapter sequences you should write to Illumina tech 
support TechSupport@illumina.com (they do not like people to share the 
list of sequences outside of their institution).

Chose about 20bp of an adapter sequence where:
1. You see the most hits with grep
2. When you run a command like:
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | head 
   you see the adapter sequence show up at the beginning of a few reads. 
   Also the -A and -B arguments should be as they show up in your data, 
   SeqPrep searches directly for these sequences without doing reverse 
   complementing.
3. Check the forward and reverse and make sure that you have roughly the 
   same number of hits via a command to count hits like: 
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | wc -l
```{r setting_seq_adapters_based_on_platform, cache=TRUE}
fwdAdapHiSeq    <- "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"  # HiSeq, Genome Quebec
revAdapHiSeq    <- "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"  # HiSeq, Genome Quebec

# Notice that the adapter sequences we chose when processing the MiSeq reads
# is from the same region we are choosing for our HiSeq reads, only shorter:
fwdAdapMiSeq <- "AGATCGGAAGAGCACAC"   # MiSeq
revAdapMiSeq <- "AGATCGGAAGAGCGTCGT"  # MiSeq

fwdAdapIonT  <- "CCATCTCATCCCTGCGTGTCTCCGACTCAG" # "A" adapter sequence for IonTorrent
revAdapIonT  <- "CCTCTCTATGGGCAGTCGGTGAT"        # "trP1" adapter sequence for IonTorrent

if(platform == 1){
    fwdAdap <- fwdAdapMiSeq
    revAdap <- revAdapMiSeq
    print('Your sequencing platform was set to the Illumina MiSeq')} else if 
(platform == 2){
    fwdAdap <- fwdAdapHiSeq
    revAdap <- revAdapHiSeq
    print('Your sequencing platform was set to the Illumina HiSeq')} else if
(platform == 3){
    fwdAdap <- fwdAdapIonT
    revAdap <- revAdapIonT
    print('Your sequencing platform was set to the Ion Torrent')} else {
        rm(fwdAdap, revAdap)
        print('You either didn\'t specify a valid sequence platform, or none was provided')
    }
fwdAdap
revAdap
```

The user does not alter the variables below. 
```{r settingToQsubWithinRStudio, cache=TRUE}
Sys.setenv(PATH=paste('/opt/gridengine/bin/linux-x64',Sys.getenv('PATH'),sep= ':'))
```


The following chunk will integrate the user-defined variables from the previous chunk into the script.
```{r creating_dir_for_analysis, cache=TRUE}
# Create the analysis directory:
dir.create(paste(sharedPath, analysis, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

# Set the path to the analysis directory:
sharedPathAn <- paste(sharedPath, analysis, sep="")

# Create the analysis directory:
dir.create(paste(sharedPathAn, seqDataDir, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)
# Set the path the fastq directory:
pathFastq <- paste(sharedPathAn, seqDataDir, "/", sep = "")
```

Path to the biocluster-installed tools:
```{r biocluster_tools_paths, cache=TRUE}
prinSeqPath      <- "/opt/bio/prinseq-lite/prinseq-lite"
prinSeqGraphPath <- "/opt/bio/prinseq-lite/prinseq-graphs"
seqPrepPath      <- "/opt/bio/SeqPrep/SeqPrep"
adapterRemPath   <- "/home/CFIA-ACIA/girouxeml/prog/miniconda/bin/AdapterRemoval"
```

Below the metadata file specified by the user is copied into the analysis folder and read into R:
```{r copy_metadata_to_analysis_dir_and_read, cache=TRUE}

cmd      <- paste("cp ", metadataPath, " ", sharedPathAn, sep = "")
system(cmd)
metadata <-  read.table(paste(sharedPathAn, metadataFileAlternate, sep = ""),
                        sep = ",", header = TRUE, comment.char = "", quote = "", as.is = TRUE)
if(libraryLayout == 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, "_", 
                                    metadata$ReadDirection, ".fastq", sep = "")
} else if
(libraryLayout != 2){
    metadata$BaseCallsName <- paste(metadata$LibraryName, ".fastq", sep = "")
}
```

Copy and gunzip files:
```{r copyRaw_gunzip, cache=TRUE}
# Copy all files using multiple processors (this is a lot faster than the above)
# cmd <- with(metadata, paste("cp ", 
#                 FastqFilePath," ", 
#                 sharedPathAn, seqDataDir, "/", basename(FastqFilePath),"\n",
#                 " gunzip ", 
#                 sharedPathAn, seqDataDir, "/", basename(metadata$FastqFilePath),
#                 sep=""))
# OR

#If you want to rename the files that you are copying over, do the following.
#It is based on what you put under BaseCallsName in your adapted metadata csv.
cmd <- with(metadata, paste("cp ", 
                FastqFilePath," ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".tar.bz2","\n",
                " tar -xvjf ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".tar.bz2",
                sep=""))

# Generate qsub and bash files to complete the commands above:
prefix <- "A_copy_unzip" 
suffix <- ".sub"
MakeQsubs(cmd, prefix, suffix)
```

Clean-up step:
Remove the output files while keeping the qsub and bash file:
```{r, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the raw fastq files to the metadata table
```{r, cache=TRUE}
if(libraryLayout == 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, "_", metadata$ReadDirection, ".fastq", sep = "")}
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadata)){
        metadata$RawFastq <- paste(metadata$LibraryName, ".fastq", sep = "")
    }
}
```
The following will create a metadata table based on the library layout - paired-end or single reads.
Read pairs will be collapsed to one row per pair.
```{r, cache=TRUE}
library("reshape2")
if(libraryLayout == 2){
    metadataRawPairs <- dcast(data = metadata, LibraryName 
                              ~ ReadDirection, value.var = "BaseCallsName", FUN = c)
    metadataRawPairs$ShortName <- paste(metadataRawPairs$LibraryName)
    metadataRaw <- metadataRawPairs} else if
(libraryLayout != 2){
    metadata$ShortName <- paste(metadata$LibraryName)
    metadataRaw <- metadata} else {
        cat(c("Error: Either an incorrect number was entered for library", "\n",
              "layout (single reads = 1 and paired-end reads = 2), or no selection was", "\n",
              "specified. The default will be to consider reads single.", sep = ""))
        metadata$ShortName <- paste(metadata$LibraryName)
        metadataRaw <- metadata
        }
# We can get more specific if we want, such as when there are many samples and/or a time-course:

# metadataRawPairs$ShortName <- paste(metadataRawPairs$Condition, 
#                                     metadataRawPairs$TimePoint, 
#                                     metadataRawPairs$RNASeq_Replicate, sep = ".")
```

Looking at our raw data:
Ensure that if reads are paired-end, that they are correctly paired and ordered between read 1 and
read 2 fastq files.
```{r, cache=TRUE}
# Run FastqPairedEndValidator for the first time on the raw read pairs:
if(libraryLayout == 2){
    prefix <- "B_Validator"
    cmd <-  with (metadataRaw, paste(fastqPEValidatorPath,
                                     " ", pathFastq, R1, " ", pathFastq, R2, sep = ""))
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
        cat(c("Fastq pairend end validator will not be used because you did not specify that", "\n",
              "your reads are paired end", sep = ""))
        }
#system("qstat")
```

If reads were paired-end, and the Fastq Paired-End validator was run, the output of each pair will
be displayed on the console:
```{r, echo=FALSE, cache=TRUE}
if(libraryLayout == 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
        system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".o*", sep = ""))
        cat("\n")}} else if
(libraryLayout != 2){
    cat(c("The fastq pairend end validator was not used because you specified that your", "\n",
              "reads are not paired end", sep = ""))
        }
```
To remove the output files after you are done:
```{r, echo=FALSE, cache=TRUE}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Look at the raw fastq graphs prior to adapter removal, QA, and other processing
using PrinSeq graph reports of raw reads, 
Step 1: .gd file generation:
```{r, echo=FALSE, cache=TRUE}
prefix <- "C_PrinSeq_rawGraphs"
if(libraryLayout == 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$R1, prefix, "rawGraphs", metadataRaw$R2)
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)} else if
(libraryLayout != 2){
    cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$RawFastq, prefix, "rawGraphs")
    suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
}
```

Add the name of the raw graphs .gd files to the 
metadata table:
```{r echo = FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$RawGraphName <- paste(metadataRaw$LibraryName, ".rawGraphs.gd", sep = "") 
}
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

PrinSeq graph reports of raw reads. 
Step 2: html file generation:
```{r echo = FALSE, cache = TRUE}
prefix2 <- "C2_PrinSeqRawGraphs"
cmd <- MakePrinSeqHTML(metadataRaw, prefix, metadataRaw$RawGraphName)
suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```
If ever you need to upload the .gd file on the PrinSeq web server to generate the html files:
http://edwards.sdsu.edu/cgi-bin/prinseq/prinseq.cgi?report=1 
You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
rm(prefix2)
```

Merging and adapter removal before processing:
Adapter detection:
```{r echo = FALSE, cache = TRUE}
if(libraryLayout == 2){
for (k in 1:nrow(metadataRaw)) {
  cat(c(k, metadataRaw$R1[k]))
  system(paste("cat ", pathFastq, metadataRaw$R1[k], " | head -n 1000000 | grep '", 
               fwdAdap, "' | wc -l ", sep = ""))
  cat("\n")
  }
    for (k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R2[k]))
      system(paste("cat ", pathFastq, metadataRaw$R2[k], " | head -n 1000000 | grep '", 
                   revAdap, "' | wc -l ", sep = ""))
      cat("\n")
      } 
    } else if
(libraryLayout != 2){
    for (k in 1:nrow(metadataRaw)) {
        cat(c(k, metadataRaw$R1[k]))
        system(paste("cat ", pathFastq, metadataRaw$RawFastq[k], " | head -n 1000000 | grep '",
                     fwdAdap, "' | wc -l ", sep = ""))
        cat("\n")
    }
}
```


Adapter removal:   
AdapterRemoval by Mikkel Schubert can perform adapter trimming on single-end reads. It can also do 
barcode demultiplexing. SeqPrep is great for paired-end, but can't perform adapter removal on single end.   
https://github.com/MikkelSchubert/adapterremoval
```{r}
prefix <- "D_Adapter_Removal"

node <- "10" # if using >1 threads, run sub files as: 
# $ qsub -pe smp 10 -cwd -S /bin/bash D_Adapter_Removal1.sub   

if(libraryLayout == 2){
    cmd <- with(metadataRaw, 
            paste(seqPrepPath, 
                  " -f ", pathFastq, R1,
                  " -r ", pathFastq, R2,
                  " -1 ", pathFastq, LibraryName, ".adapRem.R1.fastq.gz",
                  " -2 ", pathFastq, LibraryName, ".adapRem.R2.fastq.gz",
                  " -A ", fwdAdap,
                  " -B ", revAdap,
                  " -s ", pathFastq, paste(LibraryName, ".adapRemMerged.fastq.gz", sep = ""),
                  sep = ""))} else if 
(libraryLayout != 2){
    cmd <- with(metadataRaw, 
            paste("conda activate adapterremoval && cd ", pathFastq, 
                  " && AdapterRemoval ", 
                  " --qualitymax 44 ", # any value lower fails
                  " --qualitybase-output 33 ", 
                  " --file1 ", pathFastq, RawFastq,
                  " --gzip ",
                  " --basename ", pathFastq, LibraryName, ".Q44.adapRem.fastq",
                  " --adapter1 ", fwdAdap,
                  " --adapter2 ", revAdap,
                  " --threads ", node,
                  " && conda deactivate ", sep = ""))
}
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
rm(node)
```

To show the output of each pair on the console in Rstudio:
```{r}
if(libraryLayout == 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$R1[k], metadataRaw$R2[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
    } else if
(libraryLayout != 2){
    for(k in 1:nrow(metadataRaw)) {
      cat(c(k, metadataRaw$RawFastq[k]))
      cat("\n")
      system(paste("tail ", sharedPathAn, prefix, "/", prefix, k, suffix, ".e* | head -n 10" , sep=""))
      cat("\n")
    }
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```


Add the name of the fastq files with the adapters removed to the metadata table:
```{r}
metadataRaw$adapRemFastq <- paste(metadataRaw$LibraryName, ".adapRem.fastq", sep = "")
metadataRaw$adapRemFaPath <- paste(pathFastq, metadataRaw$adapRemFastq, sep = "")
```

Pre-Processing of Raw Reads using PrinSeq::

PrinSeq Processing of Raw reads:
PrinSeq Options Setting:
```{r}
nmax           <- 1
trimLeft       <- 15
trimRight      <- 10
trimTailLeft   <- 5   # Only for RNA-Seq - There should be no poly-tails in DNA
trimTailRight  <- 5  # Only for RNA-Seq - There should be no poly-tails in DNA
trimQualWindow <- 7 # To make this less conservative, increase from 3 to 7
trimQualType   <- "mean"
trimQualRight  <- 10 # Consider reducing from 30 to 10 initially
trimQualLeft   <- 10  # Consider reducing from 30 to 10 initially
trimQualRule   <- "lt"
lcMethod       <- "dust"
lcThreshold    <- 7
outGood        <- "processed_merged"    # Define by user
outBad         <- "null"
minLen         <- 100        # Consider reducing from 100 to 60? initially
```

For the pre-processing with PrinSeq we have three steps, with three 
sets of qsubs each:

1. Processing input raw reads with the PrinSeq trim and filtering options
2. Generating graph files of the processed reads
3. Generating html files using the graph files to visualize the outputs

For each set of qsubs, the .log, .gd, and .html outputs are sent to the 
first folder that also has the first stage qsub and bash files. 
The processed reads are output to the pathfastq folder.

PrinSeq Processing of merged reads:
First stage of quality pre-processing with PrinSeq:

1-1. 
Filter raw.fastq output from SeqPrep or AdapterRemoval by quality: Note, with 
merging with SeqPrep during adapter removal, the reads are already 
filtered and are of high quality as only the high quality reads can 
be merged.
```{r}
prefix <- "E_PrinSeqGraphQualTrim"

# I revised the function, so look to RNASeq script for how to make this work.
cmd = with(metadataRaw, 
           paste("zcat ", adapRemFaPath, ".gz", " | ", 
                 prinSeqPath, 
                 " -fastq stdin ",
                 #" -fastq ",             adapRemFaPath,
                 " -trim_qual_window ",  trimQualWindow,
                 " -trim_qual_type ",    trimQualType, 
                 " -trim_qual_right ",   trimQualRight,
                 " -trim_qual_rule ",    trimQualRule,
                 " -out_good ",          paste(pathFastq, LibraryName, ".2processedRaw", sep = ""),
                 " -out_bad  ",          outBad,
                 " -verbose ",
                 " -no_qual_header ",
                 " -log ",               sharedPathAn, prefix, "/", LibraryName, ".2processedRaw.log",
                 sep = ""))
cmd
suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
```

Add name of quality-filtered reads .fastq files to the metadata 
tabel:
```{r}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$processed1Fastq <- paste(metadataRaw$LibraryName, ".2processedRaw.fastq", sep = "") 
}
```
[prinseq-lite-0.20.4] [10/22/2018 15:03:19] Executing PRINSEQ with command: "perl prinseq-lite.pl -fastq stdin -trim_qual_right 10 -trim_qual_type mean -trim_qual_rule lt -trim_qual_window 7 -trim_qual_step 1 -log /isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory/colletotrichum/E_PrinSeqGraphQualTrim/colleto_IonT_2018_1.2processedRaw.log -verbose -out_good /isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory/colletotrichum/ionT_data/colleto_IonT_2018_1.2processedRaw -out_bad null -no_qual_header"
[prinseq-lite-0.20.4] [10/22/2018 15:03:19] Parsing and processing input data: "stdin"
[prinseq-lite-0.20.4] [10/22/2018 15:43:23] Done parsing and processing input data
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Input sequences: 20,668,664
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Input bases: 5,860,988,762
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Input mean length: 283.57
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Good sequences: 20,668,664 (100.00%)
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Good bases: 5,860,866,230
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Good mean length: 283.56
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Bad sequences: 0 (0.00%)
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] Sequences filtered by specified parameters:
[prinseq-lite-0.20.4] [10/22/2018 15:43:24] none


To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Gzip the fastq reads that were INPUT to the PrinSeq processing in step 1-1, 
we won't need them and the next step in 1-2 will be using the OUTPUT processed 
reads. 
```{r}
# I performed this directly on the command line while the previous prinseq was running.
# prefix <- "C_gzipRaw"
# cmd <- with(metadata, paste("gzip ", pathFastq, metadata$RawFastq, sep=""))
# 
# suffix <- ".sub"  
# MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
# RemoveQsubTempFiles(sharedPathAn, prefix)
```

1-2.
Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix <- "E_PrinSeqGraphQualTrim"
prefix2 <- "E2_PrinSeqGraph"

cmd <- MakePrinSeqGraphFiles(metadataRaw, metadataRaw$processed1Fastq,
                             prefix, "2processedRaw")
cmd
suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

You can follow the progress of the PrinSeq graph generation run with the following:
```{r, echo=FALSE, cache=TRUE}
for(k in 1:nrow(metadataRaw)){
    cat(c(k, metadataRaw$LibraryName[k]))
    cat("\n")
    system(paste("cat ", sharedPathAn, prefix2, "/", prefix2, k, suffix, ".e*", sep = ""))
    cat("\n")}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Add name of quality-filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$processed1GraphName <- paste(metadataRaw$LibraryName, ".2processedRaw.gd", sep = "") 
}
```

*** Directory and commands created, need to run it.
1-3.
PrinSeq graph reports of first-stage html file generation:
**Instead of putting in the filename manually, refer to metadata for it.
```{r}
prefix3 <- "E3_PrinSeqHtml"
cmd <- MakePrinSeqHTML(metadataRaw, prefix, metadataRaw$processed1GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

*** Not yet done:
Gzip the fastq reads that were output to the PrinSeq processing in step 2-1, 
input reads stayed compressed - no need to compress those. Had to stop this
testing of submitting by qsub.
```{r}
prefix3 <- "G_gzipProcessed"

cmd <- with(metadata, paste("gzip ", pathFastq, metadataRaw$processed1Fastq, sep = ""))
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

Fourth and LAST stage of quality pre-processing with PrinSeq:
Filtering of reads by complexity (DUST) and minimum length
4-1.
```{r}
prefix <- "F_PrinSeqDustMinLen"

cmd <- with(metadataRaw, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -min_len ",        minLen,
                  " -lc_method ",      lcMethod,
                  " -lc_threshold ",   lcThreshold,
                  " -out_good stdout ",
                  " -out_bad  ",       outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",            paste(sharedPathAn, prefix, "/", LibraryName, ".3processed.log", 
                                             sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName, ".3processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
rm(minLen, lcMethod, lcThreshold, outBad)
```

Estimate size of input data for status report (this might take a while for large files)
        done
Parse and process input data
        done
Clean up empty files
        done
Input and filter stats:
        Input sequences: 20,668,664
        Input bases: 5,860,866,230
        Input mean length: 283.56
        Good sequences: 20,368,185 (98.55%)
        Good bases: 5,840,272,011
        Good mean length: 286.74
        Bad sequences: 300,479 (1.45%)
        Bad bases: 20,594,219
        Bad mean length: 68.54
        Sequences filtered by specified parameters:
        min_len: 297433
        lc_method: 3046

```{r}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$processed2Fastq <- paste(metadataRaw$LibraryName, ".3processed.fastq", sep = "") 
}
for(k in 1:nrow(metadata)){
  metadataRaw$finalProcessedPath <- paste(pathFastq, "/", metadataRaw$LibraryName, ".3processed.fastq", sep = "") 
}
```
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

4-2
Generate PrinSeq graph files (.gd) for the fastq generated the previously:   
```{r}
prefix2 <- "F2_PrinSeqDustMinLength"

cmd <- MakePrinSeqGraphFiles2(metadataRaw, metadataRaw$processed2Fastq, prefix, "3processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
```

Add name of Dust and MinLen filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadataRaw)){
  metadataRaw$processed2GraphName <- paste(metadataRaw$LibraryName, ".3processed.gd", sep = "") 
}
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

```{r}
system("/opt/gridengine/bin/linux-x64/qstat") # Remove qsub temp when qstat returns nothing.
# RemoveQsubTempFiles(sharedPathAn, prefix)
```

```{r}
prefix3 <- "F3_PrinSeqHtml"
cmd <- MakePrinSeqHTML(metadataRaw, prefix, metadataRaw$processed2GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

Gather fasta data required for all assemblies:
```{r}
library(data.table)
metadata_dt <- as.data.table(metadataRaw)
setkey(metadata_dt, ScientificName, LibraryName, processed2Fastq, finalProcessedPath)

head(metadata_dt)
key(metadata_dt)
metadataAssembly <- metadata_dt[, c("ScientificName", "LibraryName", "processed2Fastq", "finalProcessedPath"), with=FALSE]
sppAbbrv <- c("colleto" )
metadataAssembly$SppAbbr <- sppAbbrv
```

Assembling with Newbler
Must first gunzip the fastq as Newbler can't use compressed files!
```{r}
prefix <- "GunZipForNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gunzip ", paste(metadataAssembly$finalProcessedPath, ".gz", sep = ""),
                  sep = ""))
}

suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

```{r}
newblerPath <- "/opt/bio/454/bin/newbler"
runAssPath  <- "/opt/bio/454/bin/runAssembly"

prefix <- "Assembly_Newbler"
node <- "20"
for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
                paste(runAssPath, 
                      " -o ", paste(sharedPath, analysis, prefix, "/", metadataAssembly$LibraryName, sep = ""),
                      " -cpu ", node, " ",    paste(metadataAssembly$finalProcessedPath, sep = ""), 
                      sep = ""))
}
cmd[1] # cmd to re-run Lari only due to previous run crash   
suffix <- ".sub" 

MakeQsubs(cmd, prefix, suffix)
# MakeQsubs(cmd[1], prefix2, suffix, node) # For re-running Lari due to previous run crash.
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the assembled contigs paths from Newbler to the metadata table:
```{r}
for(k in 1:nrow(metadataAssembly)){
  metadataAssembly$NewblerFnaPath <- paste(sharedPathAn, "Assembly_Newbler/", metadataAssembly$LibraryName,
                                           "/454LargeContigs.fna", sep = "")}
```

*** Performed the following chunk on the command line - although such large files took a while and may have been
safer to run as qsub in case of interuption.
Must first gzip the fastq after Newbler assembly to save space!
```{r}
prefix <- "GZipAfterNewbler"

for(i in 1:nrow(metadataAssembly)){
    cmd <- with(metadataAssembly, 
            paste(" gzip ", paste(metadataAssembly$finalProcessedPath, sep = ""),
                  sep = ""))
}
cmd
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix)
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

We need to fix the Newbler Assembly contig names:
Key issue I had was that there were sequence descriptions after the sequence name
of each contig inthe assembly files from Newbler, and this was causing the tool to be unable to 
create files from and process any of the sequences. If you want to remove the description and 
if your headers are structured like that: 
"> + id + space + description"

Once this part was removed, the tool worked.

i.e.,

>contig00001 1203988 12890445
agccctgcgatcgatcgggctagctagc

using sed:
$ sed -e 's/^\(>[^[:space:]]*\).*/\1/' colleto_assembly_largeContigs.fna > colleto_assembly_largeContigs.fixedNames.fna

new format:
>contig00001
agccctgcgatcgatcgggctagctagc

Add the name of the fixed assemblies to the metadata table:
```{r}
metadataAssembly$FixedNewAssemName <- paste(sharedPathAn, "Assembly_Newbler/", metadataAssembly$LibraryName, "/",
                                            metadataAssembly$SppAbbr, "_assembly_largeContigs.fixedNames.fna", sep = "")
```

Print the metadata tables:
```{r}
write.table(metadataRaw, file = file.path(referencesPath, "colleto_ionT_2018_1_metadata_processed_Oct2018.csv"),
            sep = ",", row.names = TRUE, col.names = NA, quote = FALSE)

write.table(metadataAssembly, file = file.path(referencesPath, "colleto_ionT_2018_1_metadata_Assembly_Oct2018.csv"),
            sep = ",", row.names = TRUE, col.names = NA, quote = FALSE)
```

```{r}
# CFIA-Ottawa-Fallowfield user directory programs:
programsPath    <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/prog/"
buscoPath       <- paste(progPath, "busco/scripts/run_BUSCO.py", sep = "")
buscoPezDataSet <- paste(programsPath, "busco_datasets/pezizomycotina_odb9/", sep = "")
buscoSorDataSet <- paste(programsPath, "busco_datasets/sordariomyceta_odb9", sep = "")
buscoFunDataSet <- paste(programsPath, "busco_datasets/fungi_odb9", sep = "")
buscoEukDataSet <- paste(programsPath, "busco_datasets/eukaryota_odb9/", sep = "")
```

Create a directory for thr busco outputs:
```{r}
for(k in 1:nrow(metadataAssembly)){
    dir.create(paste(sharedPathAn, metadataAssembly$ScientificName[k], "_BuscoAnalyses", sep = ""),
                     showWarnings = TRUE, recursive = FALSE)}
metadataAssembly$BuscoDir <- paste(sharedPathAn, metadataAssembly$ScientificName, "_BuscoAnalyses/", sep = "")
```

Run BUSCO for assembly evaluation:
```{r}
prefix1 <- "busco_assembly"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemName,
                     " -o assembly_eval_largeContigs_Sordariomyceta ", " -c ", node,
                     " -l ", buscoSorDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix1, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```

Run BUSCO for assembly evaluation:
```{r}
prefix2 <- "busco_assembly_fungi"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemName,
                     " -o assembly_eval_largeContigs_Fungi ", " -c ", node,
                     " -l ", buscoFunDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```

Run BUSCO for assembly evaluation:
```{r}
prefix3 <- "busco_assembly_Pezizomycotina"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemName,
                     " -o assembly_eval_largeContigs_Pezizomycotina ", " -c ", node,
                     " -l ", buscoPezDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```
Run BUSCO for assembly evaluation:
```{r}
prefix4 <- "busco_assembly_Eukaryota"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemName,
                     " -o assembly_eval_largeContigs_Eukaryota ", " -c ", node,
                     " -l ", buscoEukDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix4, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```
**To remove the output files after you are done:**
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix1); RemoveQsubTempFiles(sharedPathAn, prefix2)
RemoveQsubTempFiles(sharedPathAn, prefix3); RemoveQsubTempFiles(sharedPathAn, prefix4)
```

Try busco using the assembly with all contigs, not just large contigs:
```{r}
metadataAssembly$FixedNewAssemNameAllcontigs <- paste(sharedPathAn, seqDataDir, "/",
                                                      "colleto_assembly_allContigs.fna", sep = "")

```
Run BUSCO for assembly evaluation:
```{r}
prefix1 <- "busco_assembly_allContigs_Sordariomyceta"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemNameAllcontigs,
                     " -o assembly_eval_allContigs_Sordariomyceta ", " -c ", node,
                     " -l ", buscoSorDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix1, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```
Run BUSCO for assembly evaluation:
```{r}
prefix2 <- "busco_assembly_allContigs_fungi"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemNameAllcontigs,
                     " -o assembly_eval_AllContigs_Fungi ", " -c ", node,
                     " -l ", buscoFunDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix2, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```

Run BUSCO for assembly evaluation:
```{r}
prefix3 <- "busco_assembly_allContigs_Pezizomycotina"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemNameAllcontigs,
                     " -o assembly_eval_AllContigs_Pezizomycotina ", " -c ", node,
                     " -l ", buscoPezDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix3, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```
Run BUSCO for assembly evaluation:
```{r}
prefix4 <- "busco_assembly_allContigs_Eukaryota"
node   <- 1
cmd    <- with(metadataAssembly,
               paste("conda activate makerenv && ",
                     "cd ", BuscoDir, " && ",
                     "python ", buscoPath, " -i ", FixedNewAssemNameAllcontigs,
                     " -o assembly_eval_AllContigs_Eukaryota ", " -c ", node,
                     " -l ", buscoEukDataSet, " -m genome --long ",
                     # " --restart ", 
                     # " --force ",
                     " && conda deactivate ",
                     sep = ""))
cmd
suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix4, suffix, node)
# Note, if the run fails, restart the run with the following "--restart", it will continue from where it left off. However, check the 
# config.ini file in ~/prog/busco/config/ to make sure that restart is set to True, and that you adjust to the correct cpus number.
```
**To remove the output files after you are done:**
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix1); RemoveQsubTempFiles(sharedPathAn, prefix2)
RemoveQsubTempFiles(sharedPathAn, prefix3); RemoveQsubTempFiles(sharedPathAn, prefix4)
```