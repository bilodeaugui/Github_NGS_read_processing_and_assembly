# Installing the required packages for R:
# This is to be done in the R command line and not in R studio
#source("http://www.Bioconductor.org/biocLite.R")
#biocLite("BiocUpgrade")
################################################################################
# Getting started in R
# Set the working directory > setwd("~/")
# Check version installed
################################################################################
#Building the STAR Reference Genome Index:
```{r}
# library(knitr)
# source("http://www.Bioconductor.org/biocLite.R")
# biocLite("BiocUpgrade")
install.packages("seqinr")
install.packages("rentrez")
# I can now source my functions and call them! Set the working directory to the top
# level of the project.
# To call the function, do: 
source("R/MakeQsubs.R")
source("R/RemoveQsubTempFiles.R")
source("R/PrinSeqProc.R")
```

User: 
Define the path to the shared folder where the main working directory will be.
```{r}

sharedPath <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/"

```
User:
Define the the folder in the shared folder that will hold the analyses of the 
time-course/dataset you will be working with. In our case, we have two different 
time-course experiments, Oosporogenesis and Oospore Conversion. Below we set 
which one the script will run analyses for. We also get the user to specify what 
the name of the directory that will hold the reads will be. In the case below, 
we are calling the sequencing data directory (seqDataDir) "MiSeq_data_Sci2" 
because sequencing of oospore conversion time-course reads was done on the 
in-house MiSeq and was the second run we had done on this instrument for the 
overall project. We also added Sci2 because the sequencing libraries were made 
on the SciClone robotics instrument, and also represent the second time we 
generated libraries on that instrument:
```{r}
analysis   <- "Lachnellula_willkommii_GenomeAn/"
seqDataDir <- "IonTorrent_data_Debbie1"
```

User needs to specify the adapter sequences attached to the sequencing 
reads. This will depend on how the libraries were prepared.
We prepared our libraries using the Mondrian and SciClone with library 
kits, instruments and kits by NuGen. NuGen kits are designed to work with 
Illumina sequencing platforms and generate libraries with the sequence 
structure:

5' AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCTTCCGATCT 
   (N) 
   AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC <- region to select as forward adapter
   XXXXXX 
   ATCTCGTATGCCGTCTTCTGCTTG 3'
   
3' TTACTATGCCGCTGGTGGCTCTAGATGTGAGAAAGGGATGTGCTGCGAGAAGGCTAGA 
   (N) 
   TCTAGCCTTCTCGTGTGCAGACTTGAGGTCAGTG <- region to select as reverse adapter
   XXXXXX 
   TAGAGCATACGGCAGAAGACGAAC 5'

Where each string of ‘X’ is the unique 4-, 6, or 8-base barcode from the 
L2 adaptor mix of the library construction system (where applicable) 
and (N) is the library insert.

We will need to remove any adapter sequences from our reads. We will
be doing this with SeqPrep. SeqPrep specifies that the user must first 
ensure the adapter sequences they choose are correct by doing a "grep"
on the reads first:

Before running SeqPrep make sure to check that the program's defaults 
are indeed the adapters you are looking for. Try copying the default 
forward adapter from this file and grep it against your reads doing a 
word count, also try the same with the reverse adapter with grep. You 
should see some hits. You can also try using (and validating with grep) 
-A GATCGGAAGAGCACACG -B AGATCGGAAGAGCGTCGT as parameters. To find a 
list of Illumina adapter sequences you should write to Illumina tech 
support TechSupport@illumina.com (they do not like people to share the 
list of sequences outside of their institution).

Chose about 20bp of an adapter sequence where:
1. You see the most hits with grep
2. When you run a command like:
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | head 
   you see the adapter sequence show up at the beginning of a few reads. 
   Also the -A and -B arguments should be as they show up in your data, 
   SeqPrep searches directly for these sequences without doing reverse 
   complementing.
3. Check the forward and reverse and make sure that you have roughly the 
   same number of hits via a command to count hits like: 
   cat Lane2_0d_2.fastq | head -n 1000000 | grep "INSERT ADAPTER HERE" | wc -l


```{r}
# Notice that the adapter sequences we chose when processing the HiSeq reads
# is from the same region we are choosing for our MiSeq reads, only shorter:

fwdAdapGQ    <- "AGATCGGAAGAGCACACGTCTGAACTCCAGTCA"  # Genome Quebec
revAdapGQ    <- "AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"  # Genome Quebec

fwdAdapMiSeq <- "AGATCGGAAGAGCACAC"   # MiSeq
revAdapMiSeq <- "AGATCGGAAGAGCGTCGT"  # MiSeq

adapIonTorA  <- "CCATCTCATCCCTGCGTGTCTCCGACTCAG" # "A" adapter sequence for IonTorrent
adapIonTorP1 <- "CCTCTCTATGGGCAGTCGGTGAT"        # "trP1" adapter sequence for IonTorrent

fwdAdap      <- AdapIonTorA
revAdap      <- AdapIonTorP1

```

The following paths are to directories where the references, tools and general 
requirements are located, this depends on the directories actually having been 
put there:
```{r}
toolsDirPath     <- paste(sharedPath, "tools/", sep = "")
referencesPath   <- paste(sharedPath, analysis, "References/", sep = "")
tophat2Path      <- "/opt/bio/tophat/bin/tophat2"
bowtie2BuildPath <- "/opt/bio/bowtie2/bowtie2-build"
starPath         <- "/opt/bio/STAR/STAR"
```



The user does not alter the variables below. The following chunk will integrate 
the user-defined variables from the previous chunk into the script.
```{r}
sharedPathAn <- paste(sharedPath, analysis, sep="")

# Create fastq directory in sharedPath folder based on "seqDataDir":
dir.create(paste(sharedPathAn, seqDataDir, sep = ""), 
           showWarnings = TRUE, 
           recursive    = FALSE)

pathFastq <- paste(sharedPathAn, seqDataDir, "/", sep = "")
```

Bowtie:
Creating Bowtie reference index from the fasta file: Not done for Lachnellula willkommii
```{r}

bowind <- "lachwiiRef"

cmd    <- paste(bowtie2BuildPath, 
                " -f ", pyuuRefPath,
                " ", paste(referencesPath, bowind, sep = ""),
                sep = "")
cmd
#system(cmd)
```

User:
Specify the name of the csv file you would like to use for generation of the 
metadata file if not using the csv file generated by sequencing service: 
```{r}
getwd()
metadataFileAlternate <- "WholeGenLachnwii_Metadata.csv"
metadata              <-  read.table(paste(sharedPathAn, 
                                          metadataFileAlternate,
                                          sep = ""),
                                    sep          = ",",
                                    header       = TRUE,
                                    comment.char = "", 
                                    quote        = "",
                                    as.is        = TRUE) 
```


Copy and gunzip files:
```{r}
# Copy all files using multiple processors (this is a lot faster than the above)
# cmd <- with(metadata, paste("cp ", 
#                 FastqFilePath," ", 
#                 sharedPathAn, seqDataDir, "/", basename(FastqFilePath),"\n",
#                 " gunzip ", 
#                 sharedPathAn, seqDataDir, "/", basename(metadata$FastqFilePath),
#                 sep=""))
# OR

#If you want to rename the files that you are copying over, do the following.
#It is based on what you put under BaseCallsName in your adapted metadata csv.
cmd <- with(metadata, paste("cp ", 
                FastqFilePath," ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".fastq.gz","\n",
                " gunzip ", 
                sharedPathAn, seqDataDir, "/", metadata$BaseCallsName, ".fastq.gz",
                sep=""))

# Generate qsub and bash files to complete the commands above:
prefix <- "A_copy_unzip" 
suffix <- ".sub"
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```


Clean-up step:
Remove the output files while keeping the qsub and bash file:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)

```

Add the name of the raw fastq files to the metadata table
```{r}
for(k in 1:nrow(metadata)){
  metadata$RawFastq <- paste(metadata$BaseCallsName,
                                  ".fastq", 
                                  sep = "")
}

```


Looking at our raw data:
Look at the raw fastq graphs prior to adapter removal, QA, and other processing
using PrinSeq graph reports of raw reads, Step 1: .gd file generation:
```{r}

prefix <- "B_PrinSeq_rawGraphs"
cmd <- MakePrinSeqGraphFiles(metadata, metadata$RawFastq, prefix, 
                             "rawGraphs")

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add the name of the raw graphs .gd files to the 
metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$RawGraphName <- paste(metadata$LibraryName,
                                 ".rawGraphs.gd",
                                 sep = "") 
}
```

PrinSeq graph reports of raw reads. 
Step 2: html file generation:
```{r}
prefix2 <- "B2_PrinSeqMergedRawGraphs"
cmd <- MakePrinSeqHTML(metadata, prefix, metadata$RawGraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}

RemoveQsubTempFiles(sharedPathAn, prefix2)

```

Pre-Processing of Raw Reads using PrinSeq::

PrinSeq Processing of Raw reads:
PrinSeq Options Setting:
```{r}
nmax           <- "-ns_max_n 1"
trimLeft       <- "-trim_left 15"
trimRight      <- "-trim_right 10"
trimTailLeft   <- "-trim_tail_left 5"
trimTailRight  <- "-trim_tail_right 5"
trimQualWindow <- "-trim_qual_window 3"
trimQualType   <- "-trim_qual_type mean"
trimQualRight  <- "-trim_qual_right 32" #consider 30 after running with Andre's modified gff.
trimQualLeft   <- "-trim_qual_left 32"
trimQualRule   <- "-trim_qual_rule lt"
lcMethod       <- "-lc_method dust"
lcThreshold    <- "-lc_threshold 7"
#outGood        <- "processed_merged" Define by user
outBad         <- " -out_bad null"
minLen         <- "-min_len 100"
```

For the pre-processing with PrinSeq we have three steps, with three 
sets of qsubs each:

1. Processing input raw reads with the PrinSeq trim and fitlering options
2. Generating graph files of the processed reads
3. Generating html files using the graph files to visualize the outputs

For each set of qsubs, the .log, .gd, and .html outputs are sent to the 
first folder that also has the first stage qsub and bash files. 
The processed reads are output to the pathfastq folder.

PrinSeq Processing of merged reads:
First stage of quality pre-processing with PrinSeq:

1-1. 
Filter raw.fastq output from SeqPrep by quality: Note, with 
merging with SeqPrep during adapter removal, the reads are already 
filtered and are of high quality as only the high quality reads can 
be merged.
```{r}
prefix <- "C_PrinSeqGraphQualTrim"

# I revised the function, so look to RNASeq script for how to make this work.
cmd = with(metadata, 
           paste(prinSeqPath,
                 " -fastq ",             pathFastq,  RawFastq,
                 " -trim_qual_window ",  trimQualWindow,
                 " -trim_qual_type ",    trimQualType, 
                 " -trim_qual_right ",   trimQualRight,
                 " -trim_qual_rule ",    trimQualRule,
                 " -out_good ",          paste(pathFastq, LibraryName,
                                               ".2processedRaw",
                                              sep = ""),
                 " -out_bad  ",          outBad,
                 " -verbose ",
                 " -no_qual_header ",
                 " -log ",               sharedPathAn, prefix, "/", 
                                         LibraryName, ".2processedRaw.log",
                 sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

Add name of quality-filtered reads .fastq files to the metadata 
tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1Fastq <- paste(metadata$LibraryName,
                                    ".2processedRaw.fastq",
                                    sep = "") 
}
```
To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Gzip the fastq reads that were INPUT to the PrinSeq processing in step 1-1, 
we won't need them and the next step in 1-2 will be using the OUTPUT processed 
reads. 
```{r}

cmd <- with(metadata, paste("gzip ",
                            pathFastq,
                            metadata$RawFastq,
                            sep=""))
sapply(cmd, function(x) system(x))

```

1-2.
Generate PrinSeq graph files (.gd) for the fastq generated previously:
```{r}
prefix2 <- "C2_PrinSeqGraph"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed1Fastq,
                             prefix, "2processedRaw")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```

Add name of quality-filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed1GraphName <- paste(metadata$LibraryName,
                                        ".2processedRaw.gd",
                                        sep = "") 
}

```

1-3.
PrinSeq graph reports of first-stage html file generation:
**Instead of putting in the filename manually, refer to metadata for it.
```{r}
prefix3 <- "C3_PrinSeqHtml"
cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed1GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```

Second stage of quality pre-processing with PrinSeq:
Trim left and right, and Poly-A/T tail removal, round 1
2-1.
```{r}
prefix <- "D_PrinSeqTrimLRPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed1Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
                  " -out_good ",        paste(pathFastq, LibraryName, 
                                              ".3processed", sep = ""),
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".3processed.log", 
                                              sep = ""),
                  sep = ""))

suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add name of Poly-A/T, left and right trimmed reads .fastq files to the 
metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2Fastq <- paste(metadata$LibraryName, 
                                    ".3processed.fastq",
                                    sep = "") 
}
```


2-2.
Generate PrinSeq graph files (.gd) for the fastq generated previously:
This works, but the temp files are large - so beware of disc usage.
```{r}
prefix2 <- "D2_PrinSeqGraphTrimLRPolyAT"

cmd <- MakePrinSeqGraphFiles(metadata, metadata$processed2Fastq,
                             prefix, "3processed")

# prefix5 <- "D5_PrinSeqGraphTrimLRPolyAT"
# cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed2Fastq,
#                              prefix, "3processed")


suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```


To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```


Gzip the fastq reads that were output to the PrinSeq processing in step 2-1, 
input reads stayed compressed - no need to compress those. Had to stop this
testing of submitting by qsub.
```{r}
#prefix3 <- "D3_gzip"

cmd <- with(metadata, paste("gzip ", 
                            pathFastq, 
                            metadata$processed2Fastq, 
                            sep = ""))

# sapply(cmd, function(x) system(x))

# suffix <- ".sub"  
# MakeQsubs(cmd, prefix3, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################

```


To remove the output files after you are done:
Had to not do the chunk below due to not completing associated qsub.
```{r}
# RemoveQsubTempFiles(sharedPathAn, prefix3)
```


Add name of trimmedLR/PolyAT reads .gd files to the metadata tabel: (Done)
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed2GraphName <- paste(metadata$LibraryName,
                                        ".3processed.gd",
                                        sep = "") 
}
```


2-3.
PrinSeq graph reports of second-stage html file generation:
```{r}
prefix4 <- "D4_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed2GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix4, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```


To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix4)
```


Third stage of quality pre-processing with PrinSeq:
Poly-A/T tail removal, round 2:
Repeat poly tails trimming, because after trimming ends that had AAAAATTTTT 
that has been trimmed for the poly-T will still have the poly-A string.
3-1.
```{r}
prefix <- "E_PrinSeq2ndPolyAT"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed2Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -trim_tail_left ",  trimTailLeft,
                  " -trim_tail_right ", trimTailRight,
#                   " -out_good ",        paste(pathFastq, LibraryName,
#                                               ".4processed", sep = ""),
                  " -out_good stdout ",
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".4processed.log", 
                                              sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".4processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

Add name of 2nd polyAT trimmed reads .fastq files to the 
metadataAdapRM tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed3Fastq <- paste(metadata$LibraryName, ".4processed.fastq",
                                    sep = "") 
}
```

3-2.
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "E2_PrinSeq2ndTrimPolyATgraphs"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed3Fastq,
                             prefix, "4processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```


To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix2)
```


Add name of second trimmed PolyAT reads .gd files to the metadata tabel:
```{r}

for(k in 1:nrow(metadata)){
  metadata$processed3GraphName <- paste(metadata$LibraryName, 
                                        ".4processed.gd", sep = "") 
}
```


3-3.
PrinSeq graph reports of third-stage html file generation:
```{r}
prefix3 <- "E3_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed3GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```


Fourth and LAST stage of quality pre-processing with PrinSeq:
Filtering of reads by complexity (DUST) and minimum length

4-1.
```{r}
prefix <- "F_PrinSeqDustMinLen"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed3Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -min_len ",        minLen,
                  " -lc_method ",      lcMethod,
                  " -lc_threshold ",   lcThreshold,
                  " -out_good stdout ",
                  " -out_bad  ",        outBad,
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, ".5processed.log", 
                                              sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".5processed.fastq.gz", sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```


```{r}
for(k in 1:nrow(metadata)){
  metadata$processed4Fastq <- paste(metadata$LibraryName, ".5processed.fastq",
                                    sep = "") 
}

```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```



4-2
Generate PrinSeq graph files (.gd) for the fastq generated the previously:
```{r}
prefix2 <- "F2_PrinSeq2ndTrimPolyATgraphs"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed4Fastq,
                             prefix, "5processed")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

Add name of Dust and MinLen filtered reads .gd files to the metadata tabel:
```{r}
for(k in 1:nrow(metadata)){
  metadata$processed4GraphName <- paste(metadata$LibraryName, ".5processed.gd",
                                        sep = "") 
}
```


To remove the output files after you are done:
```{r}

RemoveQsubTempFiles(sharedPathAn, prefix2)

```

4-3.
PrinSeq graph reports of third-stage html file generation:
```{r}
prefix3 <- "F3_PrinSeq_html"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed4GraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

To remove the output files after you are done:
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix3)
```




Reads show strong bimodal GC content distribution - suggestive of contamination
To investigate possible contaminating species, will blastn a small subset of
the fastq reads to see where the strongest matches are.
```{r}

# 1. Convert fastq to fasta:
# seqtk fq2fa wholeGen_Lawii.5processed.fastq.gz > wholeGen_Lawii.5processed.test.fasta

```

```{r}

# 2. Split fasta to get a smaller set to blast:

# awk 'BEGIN {n_seq=0;} /^>/ {if(n_seq%1000==0){file=sprintf("myseq%d.fa",n_seq);} 
# print >> file; n_seq++; next;} { print >> file; }' < sequences.fa

````

```{r}
# Alternate option of checking contaminants: parse fastq reads by GC content
# using PrinSeq:

cmd <- paste("perl ", prinSeqPath, " -h", sep = "")
system(cmd)

rangeGC <- "10-35"

prefix <- "G_PrinSeqDustGCRange35"

cmd <- with(metadata, 
            paste("zcat ", pathFastq, processed4Fastq, ".gz", " | ",
                  prinSeqPath,
                  " -fastq stdin ",
                  " -range_gc ",       rangeGC,
                  " -out_good stdout ",
                  " -out_bad  ",        paste(pathFastq, LibraryName, 
                                              ".5processed.GCrange35plus", 
                                              sep = ""),
                  " -verbose ",
                  " -no_qual_header ",
                  " -log ",             paste(sharedPathAn, prefix, "/", 
                                              LibraryName, 
                                              ".5processed.GCrange.log", 
                                              sep = ""),
                  " |  gzip > ", paste(pathFastq, LibraryName,
                                       ".5processed.GCrange35minus.fastq.gz", 
                                       sep = ""), 
                  sep = ""))


suffix <- ".sub"  
MakeQsubs(cmd, prefix, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################

# To remove the output files after you are done:
RemoveQsubTempFiles(sharedPathAn, prefix)


# Add the name of the contaminant/bad range gc to metadata (can remove later, 
# or adjust):
for(k in 1:nrow(metadata)){
  metadata$processed5.GC35minusFastq <- paste(metadata$LibraryName, 
                                             ".5processed.GCrange35minus.fastq",
                                             sep = "") 
}


# Generate PrinSeq graph files (.gd) for the fastq generated the previously:
prefix2 <- "G2_PrinSeqGCRangegraphs35"

cmd <- MakePrinSeqGraphFiles2(metadata, metadata$processed5.GC35minusFastq,
                             prefix, "5processed.GCrange35minus")

suffix <- ".sub"  
MakeQsubs(cmd, prefix2, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################

# To remove the output files after you are done:
RemoveQsubTempFiles(sharedPathAn, prefix2)

# Add the name of the .gd graph files to the metadata table
for(k in 1:nrow(metadata)){
  metadata$processed5.GC35minusGraphName <- paste(metadata$LibraryName, 
                                                  ".5processed.GCrange35minus.gd",
                                                  sep = "") 
}

# Generate html from the .gd graph files:
prefix3 <- "G3_PrinSeq_html35"

cmd <- MakePrinSeqHTML(metadata, prefix, metadata$processed5.GC35minusGraphName)

suffix <- ".sub"  
MakeQsubs(cmd, prefix3, suffix)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################

# To remove the output files after you are done:
RemoveQsubTempFiles(sharedPathAn, prefix3)


nameMetadata <- "Lachnellula_willkommii_WholeGen_metatdata.csv"
write.table(metadata,
            file = file.path(sharedPathAn, nameMetadata),
            sep       = ",",
            row.names = TRUE, 
            col.names = NA, 
            quote     = FALSE)
```



```{r}

# Blast qsub ncbi subset:
ncbiDbPath     <- "/isilon/biodiversity/reference/ncbi/blastdb/reference/nt/nt"
ncbiBlastnPath <- "/opt/bio/ncbi-blast+/bin/blastn"
testGenSubset  <- paste(pathFastq, "wholeGen_Lawii.5processed.GCrange35plus.test.fasta",
                        sep = "")
blastnOutFrmt  <- paste(" '", 
                        "6", " qseqid", " sallacc", " pident", " length", 
                        " mismatch", " gapopen", " qstart", " qend", " sstart", 
                        " send", " evalue", " bitscore", 
                        "'",
                        sep = "") 
maxTargetsSeqs <- 1

cmd <- paste(ncbiBlastnPath,
             " -db ",     ncbiDbPath,
             " -query ",  testGenSubset,
             " -max_target_seqs ", maxTargetsSeqs,
             " -outfmt ", blastnOutFrmt,
             " -out ",    paste(testGenSubset, ".bls",
                                sep = ""),
             sep = "")



prefix <- "testContamLachnWill_35plus"
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################



```

Try to assemble the mitochondrial genome - Newbler:
```{r}

newblerPath <- "/opt/bio/454/bin/newbler"
runAssPath  <- "/opt/bio/454/bin/runAssembly"

cmd <- with(metadata,
            paste(runAssPath,
                  " -o ", paste(pathFastq, "Assembly1_NewblerAllGCrange", sep = ""),
                  " ", pathFastq, processed4Fastq,
                  sep = ""))
prefix <- "Assembly1_NewblerAllGCrange"                
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################

````

Make a fasta file that has only contig00001 (largest contig assembled with Newbler), 
this appears to be our mitochondrial genome sequence as a blast of this resulted 
in hits to mitochondrial genomes of related species in the helotiales.
```{r}
allContigsPath  <- paste(pathFastq, "projdir-NewblerAssembly_of_wholeGen_Lawii5processed_AllGCrange/NewblerAllGCrange/454AllContigs.fna", sep = "")
allContigs      <- readAAStringSet(paste(allContigsPath), format = "fasta")
allContigsNames <- names(allContigs)
mitoContigName  <- subset(allContigsNames, grepl("contig00001", allContigsNames))
mitoContigSub   <- allContigs[which(names(allContigs) %in% mitoContigName)]
writeXStringSet(mitoContigSub, file=paste(pathFastq, "mitoRef.fasta", sep=""), append=FALSE, format="fasta")

pathMitofasta   <- paste(pathFastq, "mitoRef.fasta", sep="") 

```

Build a bowtie2 reference index for the mitochondrial genome contig:
```{r}

bowind <- "mitoRef"

cmd    <- paste(bowtie2BuildPath, 
                " -f ", pathMitofasta,
                " ", paste(pathFastq, bowind, sep = ""),
                sep = "")
system(cmd)

```

Map reads against the mitochondrial reference and extract unmapped reads,
these will be the nuclear genome reads set (non-contaminants), to a new fastq 
file (no_mito.fastq) direclty with the --un flag:
```{r}

bowtie2alignPath <- "/opt/bio/bowtie2/bowtie2"

cmd <- with(metadata,
            paste(bowtie2alignPath,
                  " --un ", paste(pathFastq, "noMito", "_", processed4Fastq, 
                                  sep = ""),
                  " -x ",   paste(pathFastq, bowind, sep = ""),
                  " -U ",   paste(pathFastq, processed4Fastq, sep = ""),
                  " -S ",   paste(pathFastq, "mitoContaminantsAlignment.sam", 
                                  sep = ""),
                  #" --no-hd ",
                  #" --no-sq ",
                  sep = ""
                  ))
system(cmd)

pathLawiiNoMito <- paste(pathFastq, "noMito", "_", metadata$processed4Fastq, sep = "")

# or:
# pathLawiiNoMito <- paste(pathFastq, "noMito_wholeGen_Lawii.5processed.fastq", sep = "")

cmd <- paste(samtools1Path,
             " view ",
             " -f 4 ", paste(pathFastq, "mitoContaminantsAlignment.sam", 
                             sep = ""),
             " > ",    paste(pathFastq, "noMito_wholeGen_Lawii.5processed", 
                             ".sam", sep = ""),
             sep = "")
system(cmd)
```

Redo assemble with Newbler on the read set that has mitochondrial reads removed:
```{r}

newblerPath <- "/opt/bio/454/bin/newbler"
runAssPath  <- "/opt/bio/454/bin/runAssembly"

cmd <- with(metadata, paste(runAssPath,
                  " -o ", paste(pathFastq, "Assembly2_NewblerNoMito", sep = ""),
                  " ",    pathLawiiNoMito, sep = ""))
prefix <- "Assembly2_NewblerNoMito"                
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
````

Get the ITS sequence? FungalITSextractor perl script:
1st: get fasta file from fastq:
```{r}
cmd <- paste(" seqtk fq2fa ", pathLawiiNoMito, " > ", 
             paste(pathFastq, "noMito_wholeGen_Lawii.5processed.fasta", sep = ""),
             sep = "")

prefix <- "fastq2fasta_NoMito"                
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```

2nd: Use fasta in ITSx perl script (remake of FungalITSextractor.pl):
```{r}
#fungalITSpath <- "/opt/bio/FungalITSextractor/FungalITSextractor.pl"
itsxPath      <- "/opt/bio/ITSx/bin/ITSx"
cmd <- paste(" perl /opt/bio/ITSx/bin/ITSx ",
             " -i ", paste(pathFastq, "noMito_wholeGen_Lawii.5processed.fasta", sep = ""),
             " -t F ",      # F here is to specify fungal
             " --save_regions all ", # This says I want all outputs, not just ITS 1 and 2
             " --table T ", # This is because I want a tble (True)
             " --cpu 6 ",   # To run this in parallel
             sep = "")
             

prefix <- "ITSx_3"                
suffix <- ".sub" 
MakeQsubs(cmd, prefix, suffix, node)
################################################################################
#####  ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
#####          watch output from this command in the console              ######
################################################################################
```











Ignore stuff below - switch to fixing Andre's script for identification

```{r}
# genBankMito <- c("NC_023540.1", "NC_001329.3", "NC_023127.1", "NC_008068.1", 
#                  "KC683708.1", "NC_010222.1", "NC_004514.1", "NC_016680.1", 
#                  "NC_025200.1", "NC_017930.1", "NC_007445.1","NC_001326.1", 
#                  "NC_009493.1", "NC_008248.1", "NC_023268.1")
```

Setting up barcode sequence references:
Querying the NCBI Database via R
http://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/chapter3.html
```{r}
library("seqinr")
choosebank() 
choosebank("genbank")
getType()
orderHelotialesList <- query("orderHelotiales", "SP=helotiales", verbose = TRUE, invisible = FALSE)
orderHelotialesrRNA <- query("orderHelotiales", "SP=helotiales AND M=rrna", verbose = TRUE, invisible = FALSE)
orderHelotialesmRNA <- query("orderHelotiales", "SP=helotiales AND M=mrna", verbose = TRUE, invisible = FALSE)
orderHelotialesITS  <- query("orderHelotiales", "SP=helotiales AND K=internal transcribed spacer", verbose = TRUE, invisible = FALSE)
orderHelotialesLSU  <- query("orderHelotiales", "SP=helotiales AND K=LSU", verbose = TRUE, invisible = FALSE)
# orderHelotialestRNA <- query("orderHelotiales", "SP=helotiales AND M=trna", verbose = TRUE, invisible = FALSE)

length(orderHelotialesList)
temp <- sapply(orderHelotialesList$req[1:10], getName, as.string = TRUE) 
temprRNA <- sapply(orderHelotialesrRNA$req, getName, as.string = TRUE) 
tempmRNA <- sapply(orderHelotialesmRNA$req[1:10], getName, as.string = TRUE)
tempITS  <- sapply(orderHelotialesITS$req, getName, as.string = TRUE)
tempLSU  <- sapply(orderHelotialesLSU$req, getName, as.string = TRUE)




annotHelITS <- getAnnot(orderHelotialesITS$req[[1]])
accession   <- annotHelITS[4]
definition  <- annotHelITS[2]

metadataAnnot$Accession <- data.frame(annotHelITS[3])

tempAll  <- c(tempITS, tempLSU)
length(tempAll)
unique(tempAll)

metadata <- data.frame(tempAll)
colnames(metadata)[1] <- "Accession"

install.packages("mygene") # package ‘mygene’ is not available (for R version 3.1.0)

# I want to make a metadata table with the following columns for each accession (to write table).
goGeneTerms <- c("Feature", "start", "end", "gene", "taxonID", "gID", "product", "Sequence",
                 "Species", "aaSequence")
i <- 1
for(i in 1:nrow(metadata)){
    queryMatch <- paste('"AC=', metadata$Accession, '"', sep = "")
    temp1 <- query("temp1", queryMatch, verbose = TRUE, invisible = FALSE )
    metadata$Sequence <- sapply(temp1$req, getSequence, as.string = TRUE)
    }


# queryAll <- query("queryAll", )

# tempLSU  <- sapply(orderHelotialesLSU$req, getSequence, as.string = TRUE)


# get a union of the lists made



```















