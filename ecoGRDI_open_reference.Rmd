
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
-----------------------------starting January 18, 2019 author: Beatriz Lujan-----------------------------------
Store databases in list:

```{r}
#SILVA DATABASE SETTINGS
SILVA_tax_type <- "consensus" #consensus, majority or none
SILVA_tax_levels <- "all" # 7 or all 
SILVA_identity <- "97" # 90, 94, 97 or 99
UNITE_identity <- "97" #97, 99 or dynamic

refSeqs <- list ("16S" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
                       "rep_set/rep_set_16S_only/", SILVA_identity ,"/silva_132_", SILVA_identity,  "_16S.fna", sep = ""),
                  "18S" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
                       "rep_set/rep_set_18S_only/", SILVA_identity ,"/silva_132_", SILVA_identity,  "_18S.fna", sep = ""),
                  "ITS" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/UNITE",
                       "/sh_refs_qiime_ver7_", UNITE_identity,  "_01.12.2017.fasta", sep =""),
                  "COI" = "/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/rdp_training_sets/terrimporter/CO1_v3.2/mydata_training/mytrainseq_nh.fasta")
refTax <- list ("16S" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
                          "taxonomy/16S_only/", SILVA_identity, "/", SILVA_tax_type, "_taxonomy_", SILVA_tax_levels, "_levels.txt", sep = ""),
                 "18S" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
                          "taxonomy/18S_only/", SILVA_identity, "/", SILVA_tax_type, "_taxonomy_", SILVA_tax_levels, "_levels.txt", sep = ""),
                 "ITS" = paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/UNITE",
                       "/sh_taxonomy_qiime_ver7_", UNITE_identity,  "_01.12.2017.txt", sep =""),
                 "COI" = "/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/rdp_training_sets/terrimporter/CO1_v3.2/mydata_training/mytrainseq_taxonomy.txt")

```

PIPELINE STEP G: G_pick_otus (CLUSTERING)

step 1: create a single fasta file with all sequences to cluster and rename the fasta headers
(into qiime acceptable headers)

```{r}
sharedPathAn <- "/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/ecoBiomics_Ian/other-otu-methods/closed-ref/"
prefix_G <- "G_pick_otus"
dir.create(paste(sharedPathAn, prefix_G, sep = ""), showWarnings = TRUE, recursive = FALSE) 
dir.create(paste(sharedPathAn, "OTU_tables", sep = ""), showWarnings = TRUE, recursive = FALSE) 
notesAn <- paste(sharedPathAn, "OTU_tables/", sep = "")
threads <- "2"

cmds <- c()
for (region in c("16S", "18S", "COI", "ITS")){
  # subData <- subset(metadataAdapRM, Region == region) 
  mergedFasta <- paste(sharedPathAn, prefix_G,  "/", region, "_adapRemMerged_trimmomatic_unsorted.fasta", sep= "")
  # for(name in subData$LibraryName) { 
  #   subData$qiimeName <- gsub("_", "-", subData$LibraryName) #replace underscores with dash for qiime
  #   newSampleName <- gsub("_", "-", name)
  #   system(paste("sed \'s/^>[:alnum:]*/>", newSampleName, "_/\' ",
  #                sharedPathAn, seqDataDir, "/", name,  ".adapRemMerged_trimmomatic.fasta >> ",
  #                mergedFasta, sep = ""))
  # }
  # cmd <- paste ("pick_open_reference_otus.py -i ", mergedFasta ," -r ", refSeqs[[region]], " -a -m usearch -o ", sharedPathAn, prefix_G,
  #               "/", region, " --suppress_taxonomy_assignment --suppress_align_and_tree -O ", threads, sep = "")
  cmd <- paste ("parallel_pick_otus_uclust_ref.py -i ", mergedFasta ," -r ", refSeqs[[region]], " -o ", sharedPathAn, prefix_G, " -O ", threads, sep = "")
   
  #cmd <- paste ("pick_otus.py -i ", mergedFasta ," -m uclust -s 0.97 -o ", sharedPathAn, prefix_G, sep = "")
  cmds <- c(cmds, cmd)
  #subData$qiimeName <- gsub("_", "-", subData$LibraryName) #replace underscores with dash for qiime
  #write.csv(subData, file = paste(sharedPathAn, "OTU_tables", "/", region,"-metadata.csv", sep = "")) 
  system(paste("echo 'parallel_pick_otus_uclust_ref.py\n\tmethod: uclust_ref\n\treference sequences: ", 
               refSeqs[[region]],"' > ", notesAn, region, "-analysis-notes.txt" , sep=""))
  
}
MakeJobs(cmds, prefix_G, threads, 5000, 172800, "yes")
```

run jobs by running jobsub_all.job

```{r}
system(paste("jobsub ", sharedPathAn, prefix_G, "/", "jobsub_all.job", sep = ""))
system(paste("rm  ", sharedPathAn, prefix_G, "/", "*.job.e*", sep = "")) #remove error files
system(paste("rm  ", sharedPathAn, prefix_G, "/", "*.job.o*", sep = "")) #remove output files
```

step 2: Add more info to the qiime log and write metadata csv that is relevant to the analysis

```{r}
for (region in unique(metadataAdapRM$Region)){
  mergedFasta <- paste(sharedPathAn, prefix_G,  "/", region, "_adapRemMerged_trimmomatic_unsorted.fasta", sep= "")
  #pickOtuVersion <- system("parallel_pick_otus_uclust_ref.py --version", intern = TRUE)
  pickOtuVersion < "Version: parallel_pick_otus_uclust_ref.py 1.9.1"
  pickOtuLog <- gsub(".fasta", "_otus.log", mergedFasta)
  system (paste("echo \'\nInput file: ", mergedFasta, "\' >> ", pickOtuLog , sep = "")) #add input file to log
  system (paste("echo \'Metadata: ", region, "-metadata.csv\' >> ", pickOtuLog , sep = "")) #add subsetting type that was used to prepare fasta file
  system (paste("echo \'", pickOtuVersion, "\' >> ", pickOtuLog , sep = "")) #add version to log
  system (paste("echo \'", Sys.time(), "\' >> ", pickOtuLog , sep = "")) #add time to log
}
```

PIPELINE STEP H: H_pick_representatives 

```{r}
prefix_H <- "H_pick_representatives"
cmds <- c()
for (region in c("16S", "18S", "COI", "ITS")){
  mergedFasta <- paste(sharedPathAn, prefix_G,  "/", region, "_adapRemMerged_trimmomatic_unsorted.fasta", sep= "")
  pickOtutxt <- gsub(".fasta", "_otus.txt", mergedFasta)
  repSeq <- paste (sharedPathAn, prefix_H, "/", region, "_representative_seqs_set.fasta" , sep = "")
  cmd <- paste("pick_rep_set.py -i ", pickOtutxt, " -f ", mergedFasta, " -m longest -o ", repSeq , sep = "")
  cmds <- c(cmds, cmd)
  system(paste("echo 'pick_rep_set.py\n\tmethod: longest' >> ", notesAn, region, "-analysis-notes.txt" , sep=""))
}
MakeJobs(cmds, prefix_H, 1, 1800, 172800, "yes")
```

run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_H, "/", "jobsub_all.job", sep = ""))
# system(paste("rm  ", sharedPathAn, prefix_H, "/", "*.job.e*", sep = "")) #remove error files
# system(paste("rm  ", sharedPathAn, prefix_H, "/", "*.job.o*", sep = "")) #remove output files
```

PIPELINE STEP I: I_identify_chimeric_seqs --> I/J steps are optional*

Removing chimeric sequences is suggested in most workflows. Snakemake v0.4 suggests this step.
Have to set a variable: $ export BLASTMAT=/opt/bio/ncbi/data/ so that blast works.
Note: Reference files are provided in the training modules, this is a 16S reference database

DEFINE REFERENCE DATABASE SETTINGS
```{r}
database_16S <- "SILVA" #greengenes or SILVA
#SILVA DATABASE SETTINGS
SILVA_tax_type <- "consensus" #consensus, majority or none
SILVA_tax_levels <- "all" # 7 or all 
SILVA_identity <- "97" # 90, 94, 97 or 99
UNITE_identity <- "97" #97, 99 or dynamic
```

```{r}
#prefix_I <- "I_identify_chimeric_seqs"
# threads <- "4"
# tempFolder <- paste(sharedPathAn, prefix_I, "/", "mytemp", sep= "")
# cmds <- c()
# 
# for (region in unique(metadataAdapRM$Region)){
#   rm(refFasta)
#   rm(refTaxonomy)
#   if (region == "16S" & database_16S == "greengenes"){
#     refFasta <- "/space/project/grdi/eco/training/20170223/pipeline/snakemake-workflows-0.2/greengenes_97_otus.fasta"
#     refTaxonomy <- "/space/project/grdi/eco/training/20170223/pipeline/snakemake-workflows-0.2/greengenes_97_otu_taxonomy.txt"
#   } 
#   if (region == "16S" & database_16S == "SILVA"){
#     refFasta <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
#                        "rep_set/rep_set_16S_only/", SILVA_identity ,"/silva_132_", SILVA_identity,  "_16S.fna", sep = "")
#     refTaxonomy <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
#                           "taxonomy/16S_only/", SILVA_identity, "/", SILVA_rep_type, "_taxonomy_", SILVA_tax_levels, "_levels.txt", sep = "")
#   } 
#   if (region == "18S"){
#     refFasta <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
#                        "rep_set/rep_set_18S_only/", SILVA_identity ,"/silva_132_", SILVA_identity,  "_18S.fna", sep = "")
#     refTaxonomy <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/SILVA_132_QIIME_release/",
#                           "taxonomy/18S_only/", SILVA_identity, "/", SILVA_rep_type, "_taxonomy_", SILVA_tax_levels, "_levels.txt", sep = "")
#   }
#   if (region == "ITS"){
#     refFasta <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/UNITE",
#                        "/sh_refs_qiime_ver7_", UNITE_identity,  "_01.12.2017.fasta", sep ="")
#     refTaxonomy <- paste ("/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/databases/UNITE",
#                        "/sh_taxonomy_qiime_ver7_", UNITE_identity,  "_01.12.2017.txt", sep ="")
#   }
#   if (region == "COI"){
#     refFasta <- "/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/rdp_training_sets/terrimporter/CO1_v3.2/mydata_training/mytrainseq_nh.fasta"
#     refTaxonomy <- "/space/project/grdi/eco/groups/bilodeaug/gir001/PIRL_working/References/rdp_training_sets/terrimporter/CO1_v3.2/mydata_training/mytrainseq_taxonomy.txt"
#   }
#   repSeq <- paste (sharedPathAn, prefix_H, "/", region, "_representative_seqs_set.fasta" , sep = "")
#   chimericList <- paste(sharedPathAn, prefix_I, "/", region, "_chimera_list.txt" , sep="")
#   cmd <- paste ("mkdir ", tempFolder, "\n",
#                 "export TMPDIR=", tempFolder, "\n",
#                 "export BLASTMAT=/opt/bio/ncbi/data/\n",
#                 "time parallel_identify_chimeric_seqs.py -i ", repSeq, " -t ", refTaxonomy, " -r ", 
#                 refFasta, " -m blast_fragments -o ", chimericList, " -O ", threads, 
#                 "\nrm -r ", tempFolder, sep = "" )
#   cmds <- c(cmds, cmd)
#   system(paste("echo 'parallel_identify_chimeric_seqs.py method: BLAST\n\treference sequences: ", 
#                refFasta, "\n\treference taxonomy: ", refTaxonomy, "' >> ", notesAn, region, "-analysis-notes.txt" , sep=""))
# }
# MakeJobs(cmds, prefix_I, threads, 8000, 172800, "yes")
```
run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_I, "/", "jobsub_all.job", sep = ""))
# system(paste("rm  ", sharedPathAn, prefix_I, "/", "*.job.e*", sep = "")) #remove error files
# system(paste("rm  ", sharedPathAn, prefix_I, "/", "*.job.o*", sep = "")) #remove output files
```

PIPELINE STEP J: J_remove_chimeric_seqs --> I/J steps are optional*

```{r}
prefix_J <- "J_remove_chimeric_seqs"
cmds <- c()
for (region in c("16S", "18S", "COI", "ITS")){
  repSeq <- paste (sharedPathAn, prefix_H, "/", region, "_representative_seqs_set.fasta" , sep = "")
  #repSeq <- paste (sharedPathAn, prefix_G, "/", region, "/rep_set.fna" , sep = "")
  repSeqNoChimera <-paste (sharedPathAn, prefix_J, "/", region, "_representative_seqs_noChimera.fasta" , sep = "")
  chimericList <- paste(sharedPathAn,"denovoOTUpicking/", prefix_I, "/", region, "_chimera_list.txt" , sep="")
  #chimericList <- paste(sharedPathAn, prefix_I, "/", region, "_chimera_list.txt" , sep="")
  cmd <- paste ("time filter_fasta.py -f ", repSeq, " -o ", repSeqNoChimera, " -s ", chimericList, " -n", sep="")
  cmds <- c(cmds, cmd)
}
MakeJobs(cmds, prefix_J, 1, 3000, 172800, "yes")
```

run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_J, "/", "jobsub_all.job", sep = ""))
# system(paste("rm  ", sharedPathAn, prefix_J, "/", "*.job.e*", sep = "")) #remove error files
# system(paste("rm  ", sharedPathAn, prefix_J, "/", "*.job.o*", sep = "")) #remove output files
```

--> I/J steps are optional*: snakemake v 0.1 does not have this step, but was later added (v0.4). 
Many suggest that this step is a must. I have added an if statement in step J in case
chimeric sequence removal step is not done, it can still continue the pipeline with the 
previous fasta file. 

PIPELINE STEP K: K_classify

Assign taxonomy with confidence of 0.70 as per snakemake suggestion
Changed from parallel_assign_taxonomy_rdp.py to assign_taxonomy.py -m rdp, 
because it wasn't running easily in parallel. 

```{r}
prefix_K <- "K_classify" ## running tests with a different command 
classifyConfidence <- "0.70"
tempFolder <- paste(sharedPathAn, prefix_K, "/", "mytemp", sep= "")
cmds <- c()
threads <- "4"

for (region in c("16S", "18S", "COI", "ITS")){
  #repSeq <- paste (sharedPathAn, prefix_H, "/", region, "_representative_seqs_set.fasta" , sep = "")
  repSeqNoChimera <-paste (sharedPathAn, prefix_J, "/", region, "_representative_seqs_noChimera.fasta" , sep = "")
  if (region == "COI" || region == "ITS" ) {
    cmd <- paste ("mkdir ", tempFolder, region, "\n",
              "export TMPDIR=", tempFolder, region,  "\n",
              "export BLASTMAT=/opt/bio/ncbi/data/\n",
              "time parallel_assign_taxonomy_blast.py -i ", repSeqNoChimera, " -r ", refSeqs[[region]], " -t ", refTax[[region]],
              " -o ", sharedPathAn, prefix_K, " -O ", threads,
              "\nrm -r ", tempFolder, sep = "" )
    system(paste("echo 'parallel_assign_taxonomy_blast.py\n\tmethod: BLAST\n\tinput fasta: ", repSeqNoChimera, 
                 refSeqs[[region]], "\n\treference taxonomy: ", refTax[[region]], "' >> ", notesAn, region, "-analysis-notes.txt" , sep=""))
    
    #next()
  } else {
    cmd <- paste ("mkdir ", tempFolder, region, "\n",
                  "export TMPDIR=", tempFolder, region, "\n",
                  "time assign_taxonomy.py -m rdp -i ", repSeqNoChimera, " -r ", refSeqs[[region]], " -t ", refTax[[region]], 
                   " -c ", classifyConfidence, " -o ", sharedPathAn, prefix_K, " --rdp_max_memory 10000",  
                  #sep = "" )
                  "\nrm -r ", tempFolder, region,  sep = "" )
    system(paste("echo 'assign_taxonomy.py\n\tmethod: RDP classifier\n\tinput fasta: ", repSeqNoChimera, "\n\treference sequences: ", 
                 refSeqs[[region]], "\n\treference taxonomy: ", refTax[[region]], "\n\tconfidence: ", classifyConfidence, "' >> ", notesAn, region, "-analysis-notes.txt" , sep=""))
  }
  cmds <- c(cmds, cmd)
}
MakeJobs(cmds, prefix_K, threads, 10000, 172800, "yes") #All will run with 4, although only necessary for COI

```

run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_K, "/", "jobsub_all.job", sep = ""))
# system(paste("rm  ", sharedPathAn, prefix_K, "/", "*.job.e*", sep = "")) #remove error files
# system(paste("rm  ", sharedPathAn, prefix_K, "/", "*.job.o*", sep = "")) #remove output files
```

PIPELINE STEP L: L_make_otu 

Make OTU table as a biom file.
Biom file: the columns correspond to Samples and rows correspond to OTUs
and the number of times a sample appears in a particular OTU

```{r}
prefix_L <- "L_make_otu"
cmds <- c()

for (region in c("16S", "18S", "COI", "ITS")){
  pickOtutxt <- paste(sharedPathAn, prefix_G,  "/", region, "-adapRemMerged_trimmomatic_unsorted_otus.txt", sep="")
  #pickOtutxt <- paste(sharedPathAn, prefix_G,  "/", region, "/final_otu_map.txt", sep="")
  inputFasta <- system(paste("grep 'input fasta' ", notesAn, region, "-analysis-notes.txt",
                           " | cut -d ' ' -f 3", sep=""), intern = TRUE)
  biomTable <- paste (notesAn, region, "_otu_table.biom", sep="")
  cmd <- paste ("make_otu_table.py -i ", pickOtutxt, " -t ", refTax[[region]], " -o ", biomTable, sep="")
  cmds <- c(cmds, cmd)
  
}
MakeJobs(cmds, prefix_L, 1, 3000, 172800, "yes")
```

run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_L, "/", "jobsub_all.job", sep = ""))
# system(paste("rm  ", sharedPathAn, prefix_L, "/", "*.job.e*", sep = "")) #remove error files
# system(paste("rm  ", sharedPathAn, prefix_L, "/", "*.job.o*", sep = "")) #remove output files
```

PIPELINE STEP M: M_convert_otu_table 

Convert OTU table in biom format to tab-delimited table format.

```{r}
prefix_M <- "M_convert_otu_table"
cmds <- c()

for (region in unique(metadataAdapRM$Region)){
  biomTable <- paste (notesAn, region, "_otu_table.biom", sep="")
  otuTable <- paste (notesAn, region, "_otu_table.otu", sep="")
  cmd <- paste("biom convert -i ", biomTable, " -o ", otuTable, " --to-tsv --header-key taxonomy", sep="")
  cmds <- c(cmds, cmd)
}
MakeJobs(cmds, prefix_M, 1, 3000, 172800, "yes")

```

run jobs by running jobsub_all.job:
```{r}
system(paste("jobsub ", sharedPathAn, prefix_M, "/", "jobsub_all.job", sep = ""))
system(paste("rm  ", sharedPathAn, prefix_M, "/", "*.job.e*", sep = "")) #remove error files
system(paste("rm  ", sharedPathAn, prefix_M, "/", "*.job.o*", sep = "")) #remove output files
```